{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d34b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0 ‚Äî suprimir warnings + tqdm por STDOUT (una sola barra)\n",
    "import warnings, sys\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm as _tqdm\n",
    "    from functools import partial\n",
    "    tqdm = partial(_tqdm, file=sys.stdout, dynamic_ncols=True, mininterval=0.2, leave=True)\n",
    "except Exception:\n",
    "    def tqdm(x, **k):  # fallback si no hay tqdm\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecede0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Par√°metros:\n",
      "ASOF: 2025-10-24 10:00:00 | HORIZONS: [1, 3, 6, 12] | FREQ_MIN: 60\n"
     ]
    }
   ],
   "source": [
    "# Celda 1 ‚Äî Imports, paths y par√°metros\n",
    "# --- Imports\n",
    "import os, json, joblib\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Paths (ajust√° si tu notebook est√° en otra carpeta)\n",
    "MODEL_PATH = \"../models/03D/best_model.pkl\"\n",
    "DATA_PATH  = \"../data/curated/ecobici_model_ready.parquet\"\n",
    "OUT_DIR    = \"../predictions\"\n",
    "\n",
    "# --- Par√°metros de corrida\n",
    "ASOF       = \"2025-10-24 10:00:00\"   # fecha-hora de referencia\n",
    "HORIZONS   = [1, 3, 6, 12]           # en pasos\n",
    "FREQ_MIN   = 60                      # minutos por paso (60 = 1h)\n",
    "\n",
    "# --- Columnas clave\n",
    "Y_COL  = \"num_bikes_available\"\n",
    "ID_COL = \"station_id\"\n",
    "TS_COL = \"ts_local\"\n",
    "\n",
    "# --- Checks y setup\n",
    "assert os.path.exists(MODEL_PATH), f\"Modelo no encontrado: {MODEL_PATH}\"\n",
    "assert os.path.exists(DATA_PATH),  f\"Datos no encontrados: {DATA_PATH}\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Listo. Par√°metros:\")\n",
    "print(\"ASOF:\", ASOF, \"| HORIZONS:\", HORIZONS, \"| FREQ_MIN:\", FREQ_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ee1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2 ‚Äî Utilidades (expandir JSON, one-hot, features temporales)\n",
    "def _looks_like_json_dict(s: str) -> bool:\n",
    "    s = str(s).strip()\n",
    "    return s.startswith(\"{\") and s.endswith(\"}\")\n",
    "\n",
    "def expand_json_like_columns(df: pd.DataFrame, exclude: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Detecta columnas object con dicts (JSON-like) y las expande a num√©ricas.\"\"\"\n",
    "    df2 = df.copy()\n",
    "    obj_cols = [c for c in df2.columns if c not in exclude and df2[c].dtype == \"object\"]\n",
    "    for col in obj_cols:\n",
    "        sample = df2[col].dropna().astype(str).head(50)\n",
    "        if len(sample) == 0:\n",
    "            continue\n",
    "        if sample.map(_looks_like_json_dict).mean() >= 0.6:\n",
    "            def _parse(x):\n",
    "                try:\n",
    "                    d = json.loads(x) if isinstance(x, str) else x\n",
    "                    return d if isinstance(d, dict) else {}\n",
    "                except Exception:\n",
    "                    return {}\n",
    "            exp = df2[col].apply(_parse).apply(pd.Series)\n",
    "            if exp is not None and exp.shape[1] > 0:\n",
    "                exp = exp.add_prefix(f\"{col}_\")\n",
    "                for c in exp.columns:\n",
    "                    exp[c] = pd.to_numeric(exp[c], errors=\"coerce\").fillna(0.0)\n",
    "                df2 = pd.concat([df2.drop(columns=[col]), exp], axis=1)\n",
    "    return df2\n",
    "\n",
    "def onehot_low_card(dfX: pd.DataFrame, max_card: int = 20) -> pd.DataFrame:\n",
    "    low = [c for c in dfX.columns if dfX[c].dtype == \"object\" and dfX[c].nunique(dropna=True) <= max_card]\n",
    "    if low:\n",
    "        dfX = pd.get_dummies(dfX, columns=low, drop_first=True)\n",
    "    return dfX\n",
    "\n",
    "def make_numeric_features(dfX: pd.DataFrame) -> pd.DataFrame:\n",
    "    dfX = expand_json_like_columns(dfX, exclude=[])\n",
    "    dfX = onehot_low_card(dfX)\n",
    "    return dfX.select_dtypes(include=[\"number\"]).fillna(0.0)\n",
    "\n",
    "def time_features_from_ts(ts: pd.Timestamp) -> dict:\n",
    "    hour  = ts.hour\n",
    "    dow   = ts.dayofweek\n",
    "    month = ts.month\n",
    "    is_weekend = int(dow in (5, 6))\n",
    "    hour_sin = np.sin(2*np.pi*hour/24)\n",
    "    hour_cos = np.cos(2*np.pi*hour/24)\n",
    "    return {\n",
    "        \"hour\": hour, \"dow\": dow, \"month\": month, \"is_weekend\": is_weekend,\n",
    "        \"hour_sin\": hour_sin, \"hour_cos\": hour_cos\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f958d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones con dato ‚â§ ASOF: 393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>num_bikes_available_types</th>\n",
       "      <th>num_bikes_disabled</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>num_docks_disabled</th>\n",
       "      <th>last_reported</th>\n",
       "      <th>is_charging_station</th>\n",
       "      <th>status</th>\n",
       "      <th>is_installed</th>\n",
       "      <th>...</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>y_lag1</th>\n",
       "      <th>y_lag2</th>\n",
       "      <th>y_ma3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>{\"mechanical\": 11, \"ebike\": 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1759796035</td>\n",
       "      <td>False</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{\"mechanical\": 4, \"ebike\": 0}</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1759796033</td>\n",
       "      <td>False</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>{\"mechanical\": 7, \"ebike\": 0}</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1759796049</td>\n",
       "      <td>False</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id  num_bikes_available       num_bikes_available_types  \\\n",
       "0           2                   11  {\"mechanical\": 11, \"ebike\": 0}   \n",
       "1           3                    4   {\"mechanical\": 4, \"ebike\": 0}   \n",
       "2           4                    7   {\"mechanical\": 7, \"ebike\": 0}   \n",
       "\n",
       "   num_bikes_disabled  num_docks_available  num_docks_disabled  last_reported  \\\n",
       "0                   0                   29                   0     1759796035   \n",
       "1                   2                   22                   0     1759796033   \n",
       "2                   6                    7                   0     1759796049   \n",
       "\n",
       "   is_charging_station      status  is_installed  ...  is_closed  hour dow  \\\n",
       "0                False  IN_SERVICE             1  ...      False    21   0   \n",
       "1                False  IN_SERVICE             1  ...      False    21   0   \n",
       "2                False  IN_SERVICE             1  ...      False    21   0   \n",
       "\n",
       "   is_weekend month  hour_sin  hour_cos  y_lag1  y_lag2      y_ma3  \n",
       "0           0    10 -0.707107  0.707107    11.0    11.0  11.000000  \n",
       "1           0    10 -0.707107  0.707107     4.0     2.0   2.666667  \n",
       "2           0    10 -0.707107  0.707107     7.0     7.0   7.000000  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3 ‚Äî Cargar modelo y datos, armonizar zona horaria, tomar √∫ltima observaci√≥n ‚â§ ASOF por estaci√≥n\n",
    "model = joblib.load(MODEL_PATH)\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH).copy()\n",
    "df[TS_COL] = pd.to_datetime(df[TS_COL], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TS_COL])\n",
    "\n",
    "# Detectar tz de ts_local (puede ser None o una zona, p.ej. America/Argentina/Buenos_Aires)\n",
    "tz = getattr(df[TS_COL].dt.tz, 'zone', None) or df[TS_COL].dt.tz\n",
    "\n",
    "# Construir ASOF Timestamp y armonizar:\n",
    "ASOF_TS = pd.to_datetime(ASOF)\n",
    "if tz is not None:\n",
    "    # ts_local es tz-aware ‚Üí aseguramos que ASOF tambi√©n lo sea en la misma tz\n",
    "    if ASOF_TS.tzinfo is None:\n",
    "        ASOF_TS = ASOF_TS.tz_localize(tz)\n",
    "    else:\n",
    "        ASOF_TS = ASOF_TS.tz_convert(tz)\n",
    "else:\n",
    "    # ts_local es naive ‚Üí aseguramos que ASOF tambi√©n sea naive\n",
    "    if ASOF_TS.tzinfo is not None:\n",
    "        ASOF_TS = ASOF_TS.tz_convert(None)\n",
    "\n",
    "# Ordenar y tomar √∫ltima fila ‚â§ ASOF por estaci√≥n\n",
    "df = df.sort_values([ID_COL, TS_COL])\n",
    "latest = (\n",
    "    df[df[TS_COL] <= ASOF_TS]\n",
    "    .groupby(ID_COL, as_index=False)\n",
    "    .tail(1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Estaciones con dato ‚â§ ASOF:\", latest[ID_COL].nunique())\n",
    "latest.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b503f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,\n",
       " ['num_bikes_disabled',\n",
       "  'num_docks_available',\n",
       "  'num_docks_disabled',\n",
       "  'last_reported',\n",
       "  'is_installed',\n",
       "  'is_renting',\n",
       "  'is_returning',\n",
       "  '_file_last_updated',\n",
       "  'lat',\n",
       "  'lon'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3b ‚Äî Obtener esquema de columnas EXACTO usado en el entrenamiento\n",
    "TRAIN_SPLIT = \"../data/splits/train.parquet\"  # ajusta si tu notebook est√° en otra carpeta\n",
    "df_train_for_schema = pd.read_parquet(TRAIN_SPLIT)\n",
    "\n",
    "# Reutilizamos la MISMA funci√≥n make_X_y del notebook del entrenamiento\n",
    "# (si no la ten√©s en este notebook, copia la definici√≥n usada en train)\n",
    "def _looks_like_json_dict(s: str) -> bool:\n",
    "    s = str(s).strip()\n",
    "    return s.startswith(\"{\") and s.endswith(\"}\")\n",
    "\n",
    "def expand_json_like_columns(df: pd.DataFrame, exclude: list[str]) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    obj_cols = [c for c in df2.columns if c not in exclude and df2[c].dtype == \"object\"]\n",
    "    for col in obj_cols:\n",
    "        sample = df2[col].dropna().astype(str).head(50)\n",
    "        if len(sample) == 0:\n",
    "            continue\n",
    "        if sample.map(_looks_like_json_dict).mean() >= 0.6:\n",
    "            import json\n",
    "            def _parse(x):\n",
    "                try:\n",
    "                    d = json.loads(x) if isinstance(x, str) else x\n",
    "                    return d if isinstance(d, dict) else {}\n",
    "                except Exception:\n",
    "                    return {}\n",
    "            exp = df2[col].apply(_parse).apply(pd.Series)\n",
    "            if exp is not None and exp.shape[1] > 0:\n",
    "                exp = exp.add_prefix(f\"{col}_\")\n",
    "                for c in exp.columns:\n",
    "                    exp[c] = pd.to_numeric(exp[c], errors=\"coerce\").fillna(0.0)\n",
    "                df2 = pd.concat([df2.drop(columns=[col]), exp], axis=1)\n",
    "    return df2\n",
    "\n",
    "def onehot_low_card(dfX: pd.DataFrame, max_card: int = 20) -> pd.DataFrame:\n",
    "    low = [c for c in dfX.columns if dfX[c].dtype == \"object\" and dfX[c].nunique(dropna=True) <= max_card]\n",
    "    if low:\n",
    "        dfX = pd.get_dummies(dfX, columns=low, drop_first=True)\n",
    "    return dfX\n",
    "\n",
    "def make_X_y_train_schema(df: pd.DataFrame, y_col: str, id_col: str, ts_col: str):\n",
    "    drop_cols = [c for c in [y_col, id_col, ts_col] if c in df.columns]\n",
    "    X = df.drop(columns=drop_cols, errors=\"ignore\").copy()\n",
    "    X = expand_json_like_columns(X, exclude=[])\n",
    "    X = onehot_low_card(X)\n",
    "    X = X.select_dtypes(include=[\"number\"]).fillna(0.0)\n",
    "    y = df[y_col].astype(float).copy()\n",
    "    return X, y\n",
    "\n",
    "X_schema, _ = make_X_y_train_schema(df_train_for_schema, Y_COL, ID_COL, TS_COL)\n",
    "TRAIN_COLS = list(X_schema.columns)    # ‚Üê columna y orden exactos del entrenamiento\n",
    "len(TRAIN_COLS), TRAIN_COLS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea4a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas num√©ricas (constantes por estaci√≥n): 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['num_bikes_disabled',\n",
       " 'num_docks_available',\n",
       " 'num_docks_disabled',\n",
       " 'last_reported',\n",
       " 'is_installed',\n",
       " 'is_renting',\n",
       " 'is_returning',\n",
       " '_file_last_updated',\n",
       " 'lat',\n",
       " 'lon']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 4 ‚Äî Preparar ‚Äúconstantes por estaci√≥n‚Äù (num√©ricas) para reusar en cada horizonte\n",
    "latest_num = latest.copy()\n",
    "latest_num = latest_num.drop(columns=[c for c in [Y_COL, ID_COL, TS_COL] if c in latest_num.columns], errors=\"ignore\")\n",
    "latest_num = make_numeric_features(latest_num)\n",
    "\n",
    "# Indexar por station_id para lookup directo\n",
    "latest_num.index = latest[ID_COL].values\n",
    "\n",
    "print(\"Columnas num√©ricas (constantes por estaci√≥n):\", len(latest_num.columns))\n",
    "list(latest_num.columns)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd212f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Estaciones: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [05:11<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Celda 5 ‚Äî una sola barra de progreso (exterior)\n",
    "preds = []\n",
    "\n",
    "total_est = len(latest)\n",
    "for i in tqdm(range(total_est), desc=\"üîÑ Estaciones\"):\n",
    "    row = latest.iloc[i]\n",
    "    sid = row[ID_COL]\n",
    "\n",
    "    y_lag1 = float(row.get(\"y_lag1\", float(\"nan\")))\n",
    "    y_lag2 = float(row.get(\"y_lag2\", float(\"nan\")))\n",
    "    y_ma3  = float(row.get(\"y_ma3\", float(\"nan\")))\n",
    "    if np.isnan(y_lag1) or np.isnan(y_lag2) or np.isnan(y_ma3):\n",
    "        continue\n",
    "\n",
    "    cur_ts = ASOF_TS\n",
    "    const_feats = latest_num.loc[sid].astype(float).to_dict() if sid in latest_num.index else {}\n",
    "\n",
    "    # pod√©s mostrar info breve en la barra\n",
    "    # (ej: √∫ltimo horizonte procesado, estaci√≥n, etc.)\n",
    "    # tqdm_instance = tqdm(...) devolver√≠a un objeto, pero como usamos \"partial\" arriba, hacemos:\n",
    "    # no es necesario; si quer√©s post-fijo din√°mico:\n",
    "    # tqdm.set_postfix_str(f\"sid={sid}\")\n",
    "\n",
    "    for h in HORIZONS:\n",
    "        ts_pred = cur_ts + timedelta(minutes=FREQ_MIN * h)\n",
    "\n",
    "        feats = {\n",
    "            **time_features_from_ts(ts_pred),\n",
    "            \"y_lag1\": y_lag1, \"y_lag2\": y_lag2, \"y_ma3\": y_ma3,\n",
    "            **const_feats\n",
    "        }\n",
    "\n",
    "        X_raw = pd.DataFrame([feats]).select_dtypes(include=[\"number\"]).fillna(0.0)\n",
    "        X = X_raw.reindex(columns=TRAIN_COLS, fill_value=0.0)\n",
    "\n",
    "        yhat = float(model.predict(X)[0])\n",
    "        yhat_lo = yhat_hi = None\n",
    "        if hasattr(model, \"estimators_\") and isinstance(model.estimators_, list) and len(model.estimators_) > 1:\n",
    "            trees = np.array([t.predict(X)[0] for t in model.estimators_], dtype=float)\n",
    "            std = float(np.std(trees))\n",
    "            yhat_lo = yhat - 1.96*std\n",
    "            yhat_hi = yhat + 1.96*std\n",
    "\n",
    "        preds.append({\n",
    "            ID_COL: sid,\n",
    "            \"timestamp_pred\": ts_pred,\n",
    "            \"h\": int(h),\n",
    "            \"yhat\": yhat,\n",
    "            \"yhat_lo\": yhat_lo,\n",
    "            \"yhat_hi\": yhat_hi\n",
    "        })\n",
    "\n",
    "        # actualizaci√≥n recursiva de lags\n",
    "        y_lag2 = y_lag1\n",
    "        y_lag1 = yhat\n",
    "        y_ma3  = float(np.mean([yhat, y_lag2, y_ma3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740d7ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Predicciones guardadas en: ../predictions/predictions.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>timestamp_pred</th>\n",
       "      <th>h</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lo</th>\n",
       "      <th>yhat_hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 11:00:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 13:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 16:00:00-03:00</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 22:00:00-03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 11:00:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 13:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 16:00:00-03:00</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 22:00:00-03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-10-24 11:00:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-10-24 13:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id            timestamp_pred   h  yhat  yhat_lo  yhat_hi\n",
       "0           2 2025-10-24 11:00:00-03:00   1  11.0     11.0     11.0\n",
       "1           2 2025-10-24 13:00:00-03:00   3  11.0     11.0     11.0\n",
       "2           2 2025-10-24 16:00:00-03:00   6  11.0     11.0     11.0\n",
       "3           2 2025-10-24 22:00:00-03:00  12  11.0     11.0     11.0\n",
       "4           3 2025-10-24 11:00:00-03:00   1   4.0      4.0      4.0\n",
       "5           3 2025-10-24 13:00:00-03:00   3   4.0      4.0      4.0\n",
       "6           3 2025-10-24 16:00:00-03:00   6   4.0      4.0      4.0\n",
       "7           3 2025-10-24 22:00:00-03:00  12   4.0      4.0      4.0\n",
       "8           4 2025-10-24 11:00:00-03:00   1   7.0      7.0      7.0\n",
       "9           4 2025-10-24 13:00:00-03:00   3   7.0      7.0      7.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 6 ‚Äî Resultado y guardado\n",
    "if not preds:\n",
    "    raise RuntimeError(\"No se generaron predicciones (posible falta de lags en todas las estaciones).\")\n",
    "\n",
    "df_pred = pd.DataFrame(preds).sort_values([ID_COL, \"timestamp_pred\", \"h\"]).reset_index(drop=True)\n",
    "out_path = os.path.join(OUT_DIR, \"predictions.parquet\")\n",
    "df_pred.to_parquet(out_path, index=False)\n",
    "\n",
    "print(f\"[OK] Predicciones guardadas en: {out_path}\")\n",
    "df_pred.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055f8c5",
   "metadata": {},
   "source": [
    "üìò Descripci√≥n de los datos de salida (predictions.parquet)\n",
    "\n",
    "El archivo generado en el Paso 4 contiene las predicciones multi-horizonte de disponibilidad de bicicletas por estaci√≥n, obtenidas a partir del √∫ltimo registro disponible antes del instante de referencia ASOF.\n",
    "\n",
    "Cada fila representa una predicci√≥n puntual (y opcionalmente un intervalo) para una estaci√≥n espec√≠fica en un horizonte temporal determinado.\n",
    "\n",
    "| Columna\t|Tipo\t|Descripci√≥n |\n",
    "|-----------|-------|------------|\n",
    "|station_id\tint / str\t|Identificador √∫nico de la estaci√≥n Ecobici. |Se corresponde con el mismo station_id presente en los datos hist√≥ricos. |\n",
    "|timestamp_pred\tdatetime\t|Marca de tiempo (en formato local) que indica el momento futuro al que se refiere la predicci√≥n. |Se calcula como ASOF + h √ó FREQ_MIN. |\n",
    "|h\t|int\t|Horizonte temporal expresado en pasos. Cada paso equivale a FREQ_MIN minutos (por defecto, 60 min). Ejemplo: h=3 ‚Üí predicci√≥n a 3 horas.|\n",
    "|yhat\t|float\t|Predicci√≥n puntual del modelo: n√∫mero estimado de bicicletas disponibles en la estaci√≥n en ese instante futuro. |\n",
    "|yhat_lo\t|float (opcional)\t|L√≠mite inferior del intervalo de confianza aproximado (solo disponible si el modelo es un ensamble, ej. RandomForest). |\n",
    "|yhat_hi\t|float (opcional)\t|L√≠mite superior del intervalo de confianza aproximado. |\n",
    "|(meta)\t\t| |El dataset incluye una fila por combinaci√≥n (station_id, h) para cada timestamp_pred. |\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîç Interpretaci√≥n y uso en el dashboard\n",
    "- Eje temporal: timestamp_pred\n",
    "Permite graficar series de predicciones futuras (ej. pr√≥ximas 12 horas) para cada estaci√≥n.\n",
    "- Mapa de calor / Sem√°foro:\n",
    "    - Variable principal: yhat (bicis disponibles).\n",
    "    - Se pueden definir rangos de color:\n",
    "        - üü• 0‚Äì2 bicis ‚Üí ‚Äúcr√≠tica‚Äù\n",
    "        - üü® 3‚Äì5 bicis ‚Üí ‚Äúbaja disponibilidad‚Äù\n",
    "        - üü© > 5 bicis ‚Üí ‚Äúnormal‚Äù\n",
    "    - Estos umbrales pueden ajustarse din√°micamente en el dashboard.\n",
    "- Horizontes:\n",
    "    - Si el usuario selecciona un horizonte (p. ej. 3 horas), se filtran las filas con h == 3.\n",
    "- Intervalos de confianza:\n",
    "    - Si el dashboard incluye barras de error o transparencia, yhat_lo y yhat_hi permiten mostrar la incertidumbre asociada.\n",
    "- Integraci√≥n geogr√°fica:\n",
    "    - Para construir un mapa interactivo (Leaflet / Plotly / Folium), se puede unir esta tabla con station_information.parquet usando station_id para obtener latitud, longitud y nombre de estaci√≥n.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üí° Ejemplo de uni√≥n para visualizaci√≥n:\n",
    "```\n",
    "st_info = pd.read_parquet(\"../data/curated/station_information.parquet\")\n",
    "df_map = df_pred.merge(st_info, on=\"station_id\", how=\"left\")\n",
    "```\n",
    "\n",
    "As√≠ tendr√°s un dataframe con:\n",
    "station_id, name, lat, lon, timestamp_pred, h, yhat ‚Üí\n",
    "listo para alimentar un heatmap o dashboard de disponibilidad futura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9c88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EcoBici (Py3.10)",
   "language": "python",
   "name": "ecobici_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
