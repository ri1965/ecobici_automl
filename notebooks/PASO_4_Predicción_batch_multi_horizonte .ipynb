{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d34b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0 — suprimir warnings + tqdm por STDOUT (una sola barra)\n",
    "import warnings, sys\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm as _tqdm\n",
    "    from functools import partial\n",
    "    tqdm = partial(_tqdm, file=sys.stdout, dynamic_ncols=True, mininterval=0.2, leave=True)\n",
    "except Exception:\n",
    "    def tqdm(x, **k):  # fallback si no hay tqdm\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecede0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Parámetros:\n",
      "ASOF: 2025-10-24 10:00:00 | HORIZONS: [1, 3, 6, 12] | FREQ_MIN: 60\n"
     ]
    }
   ],
   "source": [
    "# Celda 1 — Imports, paths y parámetros\n",
    "# --- Imports\n",
    "import os, json, joblib\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Paths (ajustá si tu notebook está en otra carpeta)\n",
    "MODEL_PATH = \"../models/03D/best_model.pkl\"\n",
    "DATA_PATH  = \"../data/curated/ecobici_model_ready.parquet\"\n",
    "OUT_DIR    = \"../predictions\"\n",
    "\n",
    "# --- Parámetros de corrida\n",
    "ASOF       = \"2025-10-24 10:00:00\"   # fecha-hora de referencia\n",
    "HORIZONS   = [1, 3, 6, 12]           # en pasos\n",
    "FREQ_MIN   = 60                      # minutos por paso (60 = 1h)\n",
    "\n",
    "# --- Columnas clave\n",
    "Y_COL  = \"num_bikes_available\"\n",
    "ID_COL = \"station_id\"\n",
    "TS_COL = \"ts_local\"\n",
    "\n",
    "# --- Checks y setup\n",
    "assert os.path.exists(MODEL_PATH), f\"Modelo no encontrado: {MODEL_PATH}\"\n",
    "assert os.path.exists(DATA_PATH),  f\"Datos no encontrados: {DATA_PATH}\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Listo. Parámetros:\")\n",
    "print(\"ASOF:\", ASOF, \"| HORIZONS:\", HORIZONS, \"| FREQ_MIN:\", FREQ_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ee1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2 — Utilidades (expandir JSON, one-hot, features temporales)\n",
    "def _looks_like_json_dict(s: str) -> bool:\n",
    "    s = str(s).strip()\n",
    "    return s.startswith(\"{\") and s.endswith(\"}\")\n",
    "\n",
    "def expand_json_like_columns(df: pd.DataFrame, exclude: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Detecta columnas object con dicts (JSON-like) y las expande a numéricas.\"\"\"\n",
    "    df2 = df.copy()\n",
    "    obj_cols = [c for c in df2.columns if c not in exclude and df2[c].dtype == \"object\"]\n",
    "    for col in obj_cols:\n",
    "        sample = df2[col].dropna().astype(str).head(50)\n",
    "        if len(sample) == 0:\n",
    "            continue\n",
    "        if sample.map(_looks_like_json_dict).mean() >= 0.6:\n",
    "            def _parse(x):\n",
    "                try:\n",
    "                    d = json.loads(x) if isinstance(x, str) else x\n",
    "                    return d if isinstance(d, dict) else {}\n",
    "                except Exception:\n",
    "                    return {}\n",
    "            exp = df2[col].apply(_parse).apply(pd.Series)\n",
    "            if exp is not None and exp.shape[1] > 0:\n",
    "                exp = exp.add_prefix(f\"{col}_\")\n",
    "                for c in exp.columns:\n",
    "                    exp[c] = pd.to_numeric(exp[c], errors=\"coerce\").fillna(0.0)\n",
    "                df2 = pd.concat([df2.drop(columns=[col]), exp], axis=1)\n",
    "    return df2\n",
    "\n",
    "def onehot_low_card(dfX: pd.DataFrame, max_card: int = 20) -> pd.DataFrame:\n",
    "    low = [c for c in dfX.columns if dfX[c].dtype == \"object\" and dfX[c].nunique(dropna=True) <= max_card]\n",
    "    if low:\n",
    "        dfX = pd.get_dummies(dfX, columns=low, drop_first=True)\n",
    "    return dfX\n",
    "\n",
    "def make_numeric_features(dfX: pd.DataFrame) -> pd.DataFrame:\n",
    "    dfX = expand_json_like_columns(dfX, exclude=[])\n",
    "    dfX = onehot_low_card(dfX)\n",
    "    return dfX.select_dtypes(include=[\"number\"]).fillna(0.0)\n",
    "\n",
    "def time_features_from_ts(ts: pd.Timestamp) -> dict:\n",
    "    hour  = ts.hour\n",
    "    dow   = ts.dayofweek\n",
    "    month = ts.month\n",
    "    is_weekend = int(dow in (5, 6))\n",
    "    hour_sin = np.sin(2*np.pi*hour/24)\n",
    "    hour_cos = np.cos(2*np.pi*hour/24)\n",
    "    return {\n",
    "        \"hour\": hour, \"dow\": dow, \"month\": month, \"is_weekend\": is_weekend,\n",
    "        \"hour_sin\": hour_sin, \"hour_cos\": hour_cos\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f958d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones con dato ≤ ASOF: 393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>num_bikes_available_types</th>\n",
       "      <th>num_bikes_disabled</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>num_docks_disabled</th>\n",
       "      <th>last_reported</th>\n",
       "      <th>is_charging_station</th>\n",
       "      <th>status</th>\n",
       "      <th>is_installed</th>\n",
       "      <th>...</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>month</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>y_lag1</th>\n",
       "      <th>y_lag2</th>\n",
       "      <th>y_ma3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>{\"mechanical\": 11, \"ebike\": 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1759796035</td>\n",
       "      <td>False</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{\"mechanical\": 4, \"ebike\": 0}</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1759796033</td>\n",
       "      <td>False</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>{\"mechanical\": 7, \"ebike\": 0}</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1759796049</td>\n",
       "      <td>False</td>\n",
       "      <td>IN_SERVICE</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id  num_bikes_available       num_bikes_available_types  \\\n",
       "0           2                   11  {\"mechanical\": 11, \"ebike\": 0}   \n",
       "1           3                    4   {\"mechanical\": 4, \"ebike\": 0}   \n",
       "2           4                    7   {\"mechanical\": 7, \"ebike\": 0}   \n",
       "\n",
       "   num_bikes_disabled  num_docks_available  num_docks_disabled  last_reported  \\\n",
       "0                   0                   29                   0     1759796035   \n",
       "1                   2                   22                   0     1759796033   \n",
       "2                   6                    7                   0     1759796049   \n",
       "\n",
       "   is_charging_station      status  is_installed  ...  is_closed  hour dow  \\\n",
       "0                False  IN_SERVICE             1  ...      False    21   0   \n",
       "1                False  IN_SERVICE             1  ...      False    21   0   \n",
       "2                False  IN_SERVICE             1  ...      False    21   0   \n",
       "\n",
       "   is_weekend month  hour_sin  hour_cos  y_lag1  y_lag2      y_ma3  \n",
       "0           0    10 -0.707107  0.707107    11.0    11.0  11.000000  \n",
       "1           0    10 -0.707107  0.707107     4.0     2.0   2.666667  \n",
       "2           0    10 -0.707107  0.707107     7.0     7.0   7.000000  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3 — Cargar modelo y datos, armonizar zona horaria, tomar última observación ≤ ASOF por estación\n",
    "model = joblib.load(MODEL_PATH)\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH).copy()\n",
    "df[TS_COL] = pd.to_datetime(df[TS_COL], errors=\"coerce\")\n",
    "df = df.dropna(subset=[TS_COL])\n",
    "\n",
    "# Detectar tz de ts_local (puede ser None o una zona, p.ej. America/Argentina/Buenos_Aires)\n",
    "tz = getattr(df[TS_COL].dt.tz, 'zone', None) or df[TS_COL].dt.tz\n",
    "\n",
    "# Construir ASOF Timestamp y armonizar:\n",
    "ASOF_TS = pd.to_datetime(ASOF)\n",
    "if tz is not None:\n",
    "    # ts_local es tz-aware → aseguramos que ASOF también lo sea en la misma tz\n",
    "    if ASOF_TS.tzinfo is None:\n",
    "        ASOF_TS = ASOF_TS.tz_localize(tz)\n",
    "    else:\n",
    "        ASOF_TS = ASOF_TS.tz_convert(tz)\n",
    "else:\n",
    "    # ts_local es naive → aseguramos que ASOF también sea naive\n",
    "    if ASOF_TS.tzinfo is not None:\n",
    "        ASOF_TS = ASOF_TS.tz_convert(None)\n",
    "\n",
    "# Ordenar y tomar última fila ≤ ASOF por estación\n",
    "df = df.sort_values([ID_COL, TS_COL])\n",
    "latest = (\n",
    "    df[df[TS_COL] <= ASOF_TS]\n",
    "    .groupby(ID_COL, as_index=False)\n",
    "    .tail(1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Estaciones con dato ≤ ASOF:\", latest[ID_COL].nunique())\n",
    "latest.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b503f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,\n",
       " ['num_bikes_disabled',\n",
       "  'num_docks_available',\n",
       "  'num_docks_disabled',\n",
       "  'last_reported',\n",
       "  'is_installed',\n",
       "  'is_renting',\n",
       "  'is_returning',\n",
       "  '_file_last_updated',\n",
       "  'lat',\n",
       "  'lon'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3b — Obtener esquema de columnas EXACTO usado en el entrenamiento\n",
    "TRAIN_SPLIT = \"../data/splits/train.parquet\"  # ajusta si tu notebook está en otra carpeta\n",
    "df_train_for_schema = pd.read_parquet(TRAIN_SPLIT)\n",
    "\n",
    "# Reutilizamos la MISMA función make_X_y del notebook del entrenamiento\n",
    "# (si no la tenés en este notebook, copia la definición usada en train)\n",
    "def _looks_like_json_dict(s: str) -> bool:\n",
    "    s = str(s).strip()\n",
    "    return s.startswith(\"{\") and s.endswith(\"}\")\n",
    "\n",
    "def expand_json_like_columns(df: pd.DataFrame, exclude: list[str]) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    obj_cols = [c for c in df2.columns if c not in exclude and df2[c].dtype == \"object\"]\n",
    "    for col in obj_cols:\n",
    "        sample = df2[col].dropna().astype(str).head(50)\n",
    "        if len(sample) == 0:\n",
    "            continue\n",
    "        if sample.map(_looks_like_json_dict).mean() >= 0.6:\n",
    "            import json\n",
    "            def _parse(x):\n",
    "                try:\n",
    "                    d = json.loads(x) if isinstance(x, str) else x\n",
    "                    return d if isinstance(d, dict) else {}\n",
    "                except Exception:\n",
    "                    return {}\n",
    "            exp = df2[col].apply(_parse).apply(pd.Series)\n",
    "            if exp is not None and exp.shape[1] > 0:\n",
    "                exp = exp.add_prefix(f\"{col}_\")\n",
    "                for c in exp.columns:\n",
    "                    exp[c] = pd.to_numeric(exp[c], errors=\"coerce\").fillna(0.0)\n",
    "                df2 = pd.concat([df2.drop(columns=[col]), exp], axis=1)\n",
    "    return df2\n",
    "\n",
    "def onehot_low_card(dfX: pd.DataFrame, max_card: int = 20) -> pd.DataFrame:\n",
    "    low = [c for c in dfX.columns if dfX[c].dtype == \"object\" and dfX[c].nunique(dropna=True) <= max_card]\n",
    "    if low:\n",
    "        dfX = pd.get_dummies(dfX, columns=low, drop_first=True)\n",
    "    return dfX\n",
    "\n",
    "def make_X_y_train_schema(df: pd.DataFrame, y_col: str, id_col: str, ts_col: str):\n",
    "    drop_cols = [c for c in [y_col, id_col, ts_col] if c in df.columns]\n",
    "    X = df.drop(columns=drop_cols, errors=\"ignore\").copy()\n",
    "    X = expand_json_like_columns(X, exclude=[])\n",
    "    X = onehot_low_card(X)\n",
    "    X = X.select_dtypes(include=[\"number\"]).fillna(0.0)\n",
    "    y = df[y_col].astype(float).copy()\n",
    "    return X, y\n",
    "\n",
    "X_schema, _ = make_X_y_train_schema(df_train_for_schema, Y_COL, ID_COL, TS_COL)\n",
    "TRAIN_COLS = list(X_schema.columns)    # ← columna y orden exactos del entrenamiento\n",
    "len(TRAIN_COLS), TRAIN_COLS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea4a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas (constantes por estación): 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['num_bikes_disabled',\n",
       " 'num_docks_available',\n",
       " 'num_docks_disabled',\n",
       " 'last_reported',\n",
       " 'is_installed',\n",
       " 'is_renting',\n",
       " 'is_returning',\n",
       " '_file_last_updated',\n",
       " 'lat',\n",
       " 'lon']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 4 — Preparar “constantes por estación” (numéricas) para reusar en cada horizonte\n",
    "latest_num = latest.copy()\n",
    "latest_num = latest_num.drop(columns=[c for c in [Y_COL, ID_COL, TS_COL] if c in latest_num.columns], errors=\"ignore\")\n",
    "latest_num = make_numeric_features(latest_num)\n",
    "\n",
    "# Indexar por station_id para lookup directo\n",
    "latest_num.index = latest[ID_COL].values\n",
    "\n",
    "print(\"Columnas numéricas (constantes por estación):\", len(latest_num.columns))\n",
    "list(latest_num.columns)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd212f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Estaciones: 100%|██████████████████████████| 393/393 [05:11<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Celda 5 — una sola barra de progreso (exterior)\n",
    "preds = []\n",
    "\n",
    "total_est = len(latest)\n",
    "for i in tqdm(range(total_est), desc=\"🔄 Estaciones\"):\n",
    "    row = latest.iloc[i]\n",
    "    sid = row[ID_COL]\n",
    "\n",
    "    y_lag1 = float(row.get(\"y_lag1\", float(\"nan\")))\n",
    "    y_lag2 = float(row.get(\"y_lag2\", float(\"nan\")))\n",
    "    y_ma3  = float(row.get(\"y_ma3\", float(\"nan\")))\n",
    "    if np.isnan(y_lag1) or np.isnan(y_lag2) or np.isnan(y_ma3):\n",
    "        continue\n",
    "\n",
    "    cur_ts = ASOF_TS\n",
    "    const_feats = latest_num.loc[sid].astype(float).to_dict() if sid in latest_num.index else {}\n",
    "\n",
    "    # podés mostrar info breve en la barra\n",
    "    # (ej: último horizonte procesado, estación, etc.)\n",
    "    # tqdm_instance = tqdm(...) devolvería un objeto, pero como usamos \"partial\" arriba, hacemos:\n",
    "    # no es necesario; si querés post-fijo dinámico:\n",
    "    # tqdm.set_postfix_str(f\"sid={sid}\")\n",
    "\n",
    "    for h in HORIZONS:\n",
    "        ts_pred = cur_ts + timedelta(minutes=FREQ_MIN * h)\n",
    "\n",
    "        feats = {\n",
    "            **time_features_from_ts(ts_pred),\n",
    "            \"y_lag1\": y_lag1, \"y_lag2\": y_lag2, \"y_ma3\": y_ma3,\n",
    "            **const_feats\n",
    "        }\n",
    "\n",
    "        X_raw = pd.DataFrame([feats]).select_dtypes(include=[\"number\"]).fillna(0.0)\n",
    "        X = X_raw.reindex(columns=TRAIN_COLS, fill_value=0.0)\n",
    "\n",
    "        yhat = float(model.predict(X)[0])\n",
    "        yhat_lo = yhat_hi = None\n",
    "        if hasattr(model, \"estimators_\") and isinstance(model.estimators_, list) and len(model.estimators_) > 1:\n",
    "            trees = np.array([t.predict(X)[0] for t in model.estimators_], dtype=float)\n",
    "            std = float(np.std(trees))\n",
    "            yhat_lo = yhat - 1.96*std\n",
    "            yhat_hi = yhat + 1.96*std\n",
    "\n",
    "        preds.append({\n",
    "            ID_COL: sid,\n",
    "            \"timestamp_pred\": ts_pred,\n",
    "            \"h\": int(h),\n",
    "            \"yhat\": yhat,\n",
    "            \"yhat_lo\": yhat_lo,\n",
    "            \"yhat_hi\": yhat_hi\n",
    "        })\n",
    "\n",
    "        # actualización recursiva de lags\n",
    "        y_lag2 = y_lag1\n",
    "        y_lag1 = yhat\n",
    "        y_ma3  = float(np.mean([yhat, y_lag2, y_ma3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740d7ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Predicciones guardadas en: ../predictions/predictions.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>timestamp_pred</th>\n",
       "      <th>h</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lo</th>\n",
       "      <th>yhat_hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 11:00:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 13:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 16:00:00-03:00</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-24 22:00:00-03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 11:00:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 13:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 16:00:00-03:00</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-24 22:00:00-03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-10-24 11:00:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-10-24 13:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id            timestamp_pred   h  yhat  yhat_lo  yhat_hi\n",
       "0           2 2025-10-24 11:00:00-03:00   1  11.0     11.0     11.0\n",
       "1           2 2025-10-24 13:00:00-03:00   3  11.0     11.0     11.0\n",
       "2           2 2025-10-24 16:00:00-03:00   6  11.0     11.0     11.0\n",
       "3           2 2025-10-24 22:00:00-03:00  12  11.0     11.0     11.0\n",
       "4           3 2025-10-24 11:00:00-03:00   1   4.0      4.0      4.0\n",
       "5           3 2025-10-24 13:00:00-03:00   3   4.0      4.0      4.0\n",
       "6           3 2025-10-24 16:00:00-03:00   6   4.0      4.0      4.0\n",
       "7           3 2025-10-24 22:00:00-03:00  12   4.0      4.0      4.0\n",
       "8           4 2025-10-24 11:00:00-03:00   1   7.0      7.0      7.0\n",
       "9           4 2025-10-24 13:00:00-03:00   3   7.0      7.0      7.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 6 — Resultado y guardado\n",
    "if not preds:\n",
    "    raise RuntimeError(\"No se generaron predicciones (posible falta de lags en todas las estaciones).\")\n",
    "\n",
    "df_pred = pd.DataFrame(preds).sort_values([ID_COL, \"timestamp_pred\", \"h\"]).reset_index(drop=True)\n",
    "out_path = os.path.join(OUT_DIR, \"predictions.parquet\")\n",
    "df_pred.to_parquet(out_path, index=False)\n",
    "\n",
    "print(f\"[OK] Predicciones guardadas en: {out_path}\")\n",
    "df_pred.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055f8c5",
   "metadata": {},
   "source": [
    "📘 Descripción de los datos de salida (predictions.parquet)\n",
    "\n",
    "El archivo generado en el Paso 4 contiene las predicciones multi-horizonte de disponibilidad de bicicletas por estación, obtenidas a partir del último registro disponible antes del instante de referencia ASOF.\n",
    "\n",
    "Cada fila representa una predicción puntual (y opcionalmente un intervalo) para una estación específica en un horizonte temporal determinado.\n",
    "\n",
    "| Columna\t|Tipo\t|Descripción |\n",
    "|-----------|-------|------------|\n",
    "|station_id\tint / str\t|Identificador único de la estación Ecobici. |Se corresponde con el mismo station_id presente en los datos históricos. |\n",
    "|timestamp_pred\tdatetime\t|Marca de tiempo (en formato local) que indica el momento futuro al que se refiere la predicción. |Se calcula como ASOF + h × FREQ_MIN. |\n",
    "|h\t|int\t|Horizonte temporal expresado en pasos. Cada paso equivale a FREQ_MIN minutos (por defecto, 60 min). Ejemplo: h=3 → predicción a 3 horas.|\n",
    "|yhat\t|float\t|Predicción puntual del modelo: número estimado de bicicletas disponibles en la estación en ese instante futuro. |\n",
    "|yhat_lo\t|float (opcional)\t|Límite inferior del intervalo de confianza aproximado (solo disponible si el modelo es un ensamble, ej. RandomForest). |\n",
    "|yhat_hi\t|float (opcional)\t|Límite superior del intervalo de confianza aproximado. |\n",
    "|(meta)\t\t| |El dataset incluye una fila por combinación (station_id, h) para cada timestamp_pred. |\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "🔍 Interpretación y uso en el dashboard\n",
    "- Eje temporal: timestamp_pred\n",
    "Permite graficar series de predicciones futuras (ej. próximas 12 horas) para cada estación.\n",
    "- Mapa de calor / Semáforo:\n",
    "    - Variable principal: yhat (bicis disponibles).\n",
    "    - Se pueden definir rangos de color:\n",
    "        - 🟥 0–2 bicis → “crítica”\n",
    "        - 🟨 3–5 bicis → “baja disponibilidad”\n",
    "        - 🟩 > 5 bicis → “normal”\n",
    "    - Estos umbrales pueden ajustarse dinámicamente en el dashboard.\n",
    "- Horizontes:\n",
    "    - Si el usuario selecciona un horizonte (p. ej. 3 horas), se filtran las filas con h == 3.\n",
    "- Intervalos de confianza:\n",
    "    - Si el dashboard incluye barras de error o transparencia, yhat_lo y yhat_hi permiten mostrar la incertidumbre asociada.\n",
    "- Integración geográfica:\n",
    "    - Para construir un mapa interactivo (Leaflet / Plotly / Folium), se puede unir esta tabla con station_information.parquet usando station_id para obtener latitud, longitud y nombre de estación.\n",
    "\n",
    "⸻\n",
    "\n",
    "💡 Ejemplo de unión para visualización:\n",
    "```\n",
    "st_info = pd.read_parquet(\"../data/curated/station_information.parquet\")\n",
    "df_map = df_pred.merge(st_info, on=\"station_id\", how=\"left\")\n",
    "```\n",
    "\n",
    "Así tendrás un dataframe con:\n",
    "station_id, name, lat, lon, timestamp_pred, h, yhat →\n",
    "listo para alimentar un heatmap o dashboard de disponibilidad futura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9c88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EcoBici (Py3.10)",
   "language": "python",
   "name": "ecobici_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
