Excelente üëå ‚Äî ac√° ten√©s el archivo ONBOARDING.md listo para colgar en la ra√≠z del repo.
Est√° dise√±ado para que un nuevo colaborador entienda qu√© hace el proyecto, c√≥mo correrlo en 5 minutos y c√≥mo meterse m√°s a fondo (flujo completo y contribuci√≥n).

‚∏ª


# üö≤ Proyecto Ecobici-AutoML ‚Äî Gu√≠a de Onboarding

> **Objetivo:** predecir la disponibilidad de bicicletas en las estaciones de Ecobici Buenos Aires (8 h ‚Äì 22 h) mediante modelos AutoML, y visualizar resultados en un dashboard interactivo (Streamlit).

---

## üß≠ 1. Contexto general

Este proyecto forma parte del TP ‚Äì Fundamentos de Aprendizaje Autom√°tico.  
Utiliza datos abiertos del GCBA (APIs de Ecobici) y modelos entrenados con **PyCaret**, **H2O** y **FLAML** para predecir la disponibilidad horaria de bicicletas por estaci√≥n.  
El pipeline completo cubre desde la ingesta y generaci√≥n de features hasta la predicci√≥n y despliegue en una app local.

Estructura t√≠pica de flujo:

data/raw ‚Üí data/curated ‚Üí features ‚Üí model-ready ‚Üí AutoML ‚Üí modelo final ‚Üí predicciones ‚Üí tiles ‚Üí dashboard

---

## ‚öôÔ∏è 2. Instalaci√≥n y primer arranque (5 minutos)

### 2.1. Clonar el repositorio
```bash
git clone <URL_DEL_REPO>
cd ecobici-automl

2.2. Crear y activar el entorno

conda env create -f environment.yml
conda activate ecobici_automl

2.3. Verificar entorno y estructura

make verify-env
make repo-tree

‚úÖ Esto confirma versi√≥n de Python, librer√≠as clave y genera el √°rbol del proyecto en docs/dev/repo_tree.txt.

2.4. Revisar archivos necesarios

Asegurate de tener:
	‚Ä¢	data/curated/ ‚Üí con los .parquet ya curados.
	‚Ä¢	models/03D/best_model.pkl ‚Üí modelo entrenado.
	‚Ä¢	config/config.yaml ‚Üí configuraci√≥n por defecto.

2.5. Ejecutar la app

streamlit run app/main.py

Luego abr√≠ http://localhost:8501
Ah√≠ vas a ver el mapa de calor y la disponibilidad de bicis por estaci√≥n.

Si el puerto 8501 est√° ocupado, us√°:
streamlit run app/main.py --server.port 8502

‚∏ª

üß© 3. Entender el flujo completo (para quien quiera ‚Äúmeter mano‚Äù)

3.1. Lecturas recomendadas (orden sugerido)
	1.	README.md ‚Üí gu√≠a r√°pida del proyecto.
	2.	docs/FAA_avanzado.doc ‚Üí estructura avanzada, carpetas y scripts.
	3.	docs/Explicacion_Flujo.docx ‚Üí descripci√≥n detallada del pipeline.
	4.	docs/dev/repo_tree.txt ‚Üí mapa actualizado del repositorio.

‚∏ª

3.2. Convenci√≥n de notebooks y scripts

Etapa	Prefijo	Descripci√≥n	Carpeta / Ejemplo
00‚Äì01	Ingesta y limpieza	Lectura de datos crudos, depuraci√≥n	notebooks/01_ingesta.ipynb
02	Feature engineering	Lags, rolling, estacionalidad, dataset model-ready	02_Features.ipynb
03	AutoML	PyCaret, H2O, FLAML, comparativa final	03D_Comparativa.ipynb
04	Evaluaci√≥n y despliegue	Predicciones batch y tiles para app	04C_Despliegue_y_Predicci√≥n_Batch.ipynb

Scripts principales (en src/):
	‚Ä¢	preprocess.py ‚Üí genera dataset model-ready.
	‚Ä¢	train_pycaret.py / train_h2o.py / train_flaml.py ‚Üí entrena modelos.
	‚Ä¢	predict_batch.py ‚Üí genera predictions/ y tiles/.
	‚Ä¢	app/main.py ‚Üí dashboard (Streamlit).

‚∏ª

3.3. Flujo resumido

1Ô∏è‚É£ Ingesta:         data/raw ‚Üí data/curated
2Ô∏è‚É£ Features:        curated ‚Üí model_ready.parquet
3Ô∏è‚É£ Entrenamiento:   AutoML (03*) ‚Üí modelo final.pkl
4Ô∏è‚É£ Evaluaci√≥n:      m√©tricas en reports/
5Ô∏è‚É£ Predicci√≥n:      predict_batch.py ‚Üí predictions/ y tiles/
6Ô∏è‚É£ App:             visualizaci√≥n interactiva (Streamlit)


‚∏ª

üß† 4. Re-entrenar el modelo (camino dorado)
	1.	Confirmar data
data/curated/ecobici_model_ready.parquet
(si no existe, correr el notebook 02 o src/preprocess.py)
	2.	Entrenar (AutoML)
Abrir notebook 03* (PyCaret / H2O / FLAML).
Al finalizar, se guarda el mejor modelo en models/03D/best_model.pkl.
	3.	Generar predicciones batch

python src/predict_batch.py \
    --model "models/03D/best_model.pkl" \
    --input "data/curated/ecobici_model_ready.parquet" \
    --stations "data/curated/station_information.parquet" \
    --horizons 1 3 6 12 \
    --asof "2025-10-25 10:00:00"


	4.	Ejecutar la app

streamlit run app/main.py



‚∏ª

üß© 5. Personalizaci√≥n
	‚Ä¢	Config: config/config.yaml
	‚Ä¢	Rutas de datos, horizontes, estaci√≥n por defecto.
	‚Ä¢	App: app/main.py
	‚Ä¢	Umbrales de color (sem√°foro), textos, layout.
	‚Ä¢	Modelos: notebooks 03*
	‚Ä¢	Cambiar m√©trica (RMSE, MAE, R¬≤), semilla o tiempo de entrenamiento.

‚∏ª

üßæ 6. M√©tricas y reportes generados

Archivo	Descripci√≥n
reports/backtest_metrics_by_horizon.csv	Resultados por horizonte (1‚Äì3‚Äì6‚Äì12 h).
reports/error_by_hour_and_horizon.csv	An√°lisis horario del error.
reports/holdout_month_metrics.csv	Validaci√≥n realista (mes m√°s reciente).
reports/spatial_generalization.csv	(Opcional) evaluaci√≥n espacial.


‚∏ª

ü§ù 7. Contribuci√≥n (opcional)
	1.	Crear rama nueva:

git checkout -b feat/<descripcion>


	2.	Hacer cambios, agregar commits:

git add .
git commit -m "feat: descripci√≥n corta del cambio"


	3.	Subir la rama y abrir PR:

git push origin feat/<descripcion>


	4.	Checklist antes del merge:
	‚Ä¢	‚úÖ Entorno reproducible (make verify-env OK)
	‚Ä¢	‚úÖ Reports actualizados
	‚Ä¢	‚úÖ App funcionando con nuevo modelo

‚∏ª

üß≠ 8. Estructura general del repositorio

‚îú‚îÄ‚îÄ app/                     # Streamlit dashboard
‚îú‚îÄ‚îÄ config/                  # Archivos de configuraci√≥n YAML
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Datos crudos (bronze)
‚îÇ   ‚îú‚îÄ‚îÄ curated/             # Datos curados (silver/gold)
‚îÇ   ‚îî‚îÄ‚îÄ predictions/         # Resultados de predicciones batch
‚îú‚îÄ‚îÄ docs/                    # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ models/                  # Modelos entrenados
‚îú‚îÄ‚îÄ notebooks/               # Jupyter Notebooks por etapa
‚îú‚îÄ‚îÄ reports/                 # M√©tricas y evaluaciones
‚îú‚îÄ‚îÄ src/                     # Scripts reproducibles
‚îú‚îÄ‚îÄ Makefile                 # Atajos de flujo (make verify-env, make app, etc.)
‚îú‚îÄ‚îÄ environment.yml          # Dependencias Conda
‚îî‚îÄ‚îÄ README.md


‚∏ª

üß© 9. Notas t√©cnicas y compatibilidad
	‚Ä¢	Python: 3.10
	‚Ä¢	Entorno: ecobici_automl
	‚Ä¢	Frameworks: PyCaret, FLAML, H2O
	‚Ä¢	Java: H2O requiere JDK 11 (ver setup.sh o README H2O).
	‚Ä¢	Puertos: Streamlit ‚Üí 8501; MLflow ‚Üí 5001.
	‚Ä¢	Sistema: probado en macOS y Linux.

‚∏ª

üéØ 10. Pr√≥ximos pasos sugeridos
	‚Ä¢	Revisar docs/FAA_avanzado.doc para entender el flujo avanzado.
	‚Ä¢	Probar la app localmente.
	‚Ä¢	(Opcional) Re-entrenar modelo con un horizonte distinto.
	‚Ä¢	Abrir tu primera PR de prueba üöÄ

‚∏ª

Autor original: [Roberto Inza]
Repositorio acad√©mico: TP ‚Äì Fundamentos de Aprendizaje Autom√°tico (Ecobici AutoML)
√öltima actualizaci√≥n: 25 Oct 2025

‚∏ª
---

## üß∞ 11. Comandos r√°pidos del Makefile

El proyecto incluye un **Makefile** con atajos que facilitan el flujo completo sin abrir notebooks.

| Comando | Descripci√≥n |
|----------|--------------|
| `make verify-env` | Verifica versi√≥n de Python, librer√≠as clave y configuraci√≥n YAML. |
| `make repo-tree` | Genera un √°rbol actualizado del repositorio en `docs/dev/repo_tree.txt`. |
| `make features` | Ejecuta el pipeline de features (equivalente a etapa 02). |
| `make train` | Lanza el entrenamiento autom√°tico con el framework por defecto (PyCaret). |
| `make predict` | Genera predicciones batch y tiles para la app (`src/predict_batch.py`). |
| `make app` | Inicia la app de Streamlit (`streamlit run app/main.py`). |
| `make mlflow-ui` | (Opcional) Abre el servidor local de MLflow para visualizar experimentos. |
| `make clean` | Limpia outputs temporales y logs. |
| `make freeze` | Exporta dependencias actuales (`requirements_freeze.txt`). |

> üí° **Tip:** Pod√©s encadenar comandos, por ejemplo:  
> `make features && make train && make predict && make app`

---

**Fin del documento ‚Äî Gu√≠a de Onboarding Ecobici-AutoML**