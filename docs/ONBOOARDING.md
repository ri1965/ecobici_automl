Excelente ğŸ‘Œ â€” acÃ¡ tenÃ©s el archivo ONBOARDING.md listo para colgar en la raÃ­z del repo.
EstÃ¡ diseÃ±ado para que un nuevo colaborador entienda quÃ© hace el proyecto, cÃ³mo correrlo en 5 minutos y cÃ³mo meterse mÃ¡s a fondo (flujo completo y contribuciÃ³n).

â¸»


# ğŸš² Proyecto Ecobici-AutoML â€” GuÃ­a de Onboarding

> **Objetivo:** predecir la disponibilidad de bicicletas en las estaciones de Ecobici Buenos Aires (8 h â€“ 22 h) mediante modelos AutoML, y visualizar resultados en un dashboard interactivo (Streamlit).

---

## ğŸ§­ 1. Contexto general

Este proyecto forma parte del TP â€“ Fundamentos de Aprendizaje AutomÃ¡tico.  
Utiliza datos abiertos del GCBA (APIs de Ecobici) y modelos entrenados con **PyCaret**, **H2O** y **FLAML** para predecir la disponibilidad horaria de bicicletas por estaciÃ³n.  
El pipeline completo cubre desde la ingesta y generaciÃ³n de features hasta la predicciÃ³n y despliegue en una app local.

Estructura tÃ­pica de flujo:

data/raw â†’ data/curated â†’ features â†’ model-ready â†’ AutoML â†’ modelo final â†’ predicciones â†’ tiles â†’ dashboard

---

## âš™ï¸ 2. InstalaciÃ³n y primer arranque (5 minutos)

### 2.1. Clonar el repositorio
```bash
git clone <URL_DEL_REPO>
cd ecobici-automl

2.2. Crear y activar el entorno

conda env create -f environment.yml
conda activate ecobici_automl

2.3. Verificar entorno y estructura

make verify-env
make repo-tree

âœ… Esto confirma versiÃ³n de Python, librerÃ­as clave y genera el Ã¡rbol del proyecto en docs/dev/repo_tree.txt.

2.4. Revisar archivos necesarios

Asegurate de tener:
	â€¢	data/curated/ â†’ con los .parquet ya curados.
	â€¢	models/03D/best_model.pkl â†’ modelo entrenado.
	â€¢	config/config.yaml â†’ configuraciÃ³n por defecto.

2.5. Ejecutar la app

streamlit run app/main.py

Luego abrÃ­ http://localhost:8501
AhÃ­ vas a ver el mapa de calor y la disponibilidad de bicis por estaciÃ³n.

Si el puerto 8501 estÃ¡ ocupado, usÃ¡:
streamlit run app/main.py --server.port 8502

â¸»

ğŸ§© 3. Entender el flujo completo (para quien quiera â€œmeter manoâ€)

3.1. Lecturas recomendadas (orden sugerido)
	1.	README.md â†’ guÃ­a rÃ¡pida del proyecto.
	2.	docs/FAA_avanzado.doc â†’ estructura avanzada, carpetas y scripts.
	3.	docs/Explicacion_Flujo.docx â†’ descripciÃ³n detallada del pipeline.
	4.	docs/dev/repo_tree.txt â†’ mapa actualizado del repositorio.

â¸»

3.2. ConvenciÃ³n de notebooks y scripts

Perfecto ğŸ‘Œ
AcÃ¡ tenÃ©s el bloque listo para pegar directamente en tu archivo ONBOARDING.md, reemplazando la secciÃ³n anterior de notebooks.
El formato mantiene el estilo limpio, con Ã­conos y estructura clara en Markdown:

â¸»

ğŸ“˜ Estructura y descripciÃ³n de notebooks â€” Ecobici-AutoML

El flujo completo del proyecto se implementa mediante una secuencia de notebooks dentro de la carpeta notebooks/.
Cada notebook aborda una etapa especÃ­fica del pipeline, desde la carga de datos hasta la generaciÃ³n de predicciones para el dashboard final.
Todos los pasos se apoyan en los datos procesados del sistema Ecobici (API GCBA) y pueden ejecutarse de forma independiente o encadenada.

Notebook	Etapa	DescripciÃ³n
ğŸŸ© PASO_1_Cargar_chequear_y_preparar_features.ipynb	Ingesta y preparaciÃ³n de datos	Carga los datasets crudos provenientes de la API Ecobici, unifica las fuentes, verifica consistencia y genera variables iniciales (lags, medias mÃ³viles, estacionalidad).
ğŸŸ¨ PASO_2_Split_temporal_Train_Val_Test.ipynb	DivisiÃ³n temporal	Realiza la separaciÃ³n temporal de los datos para entrenamiento, validaciÃ³n y test, garantizando una correcta evaluaciÃ³n en escenarios futuros.
ğŸŸ¦ PASO_3_Modelo_base.ipynb	Modelo base	Construye un modelo de referencia (baseline) para medir el desempeÃ±o inicial frente a los modelos AutoML posteriores.
ğŸŸª PASO_4_PredicciÃ³n_batch_multi_horizonte.ipynb	GeneraciÃ³n de predicciones	Ejecuta predicciones por lotes a mÃºltiples horizontes (1 h, 3 h, 6 h, 12 h) y guarda los resultados en outputs/predictions/*.parquet.
ğŸŸ¥ PASO_5_EvaluaciÃ³n_Tracking.ipynb	EvaluaciÃ³n y seguimiento	Calcula mÃ©tricas de error (RMSE, MAE, RÂ², MAPE) por horizonte y hora del dÃ­a. Produce los reportes en la carpeta reports/.
ğŸŸ§ PASO_6A_AutoML_con_PyCaret.ipynb	AutoML â€“ PyCaret	Entrena y compara modelos (LightGBM, CatBoost, RF, etc.) mediante PyCaret. Registra los experimentos en MLflow.
ğŸŸ¦ PASO_6B_AutoML_Flami.ipynb	AutoML â€“ FLAML	Ejecuta un flujo alternativo de AutoML liviano con FLAML, optimizando recursos y tiempos de ejecuciÃ³n.
ğŸŸ« PASO_7_compare_models.ipynb	Comparativa final	Integra los resultados de PyCaret y FLAML, seleccionando el mejor modelo segÃºn desempeÃ±o y generalizaciÃ³n temporal.
ğŸŸ© PASO_8_predict_dashboard.ipynb	Despliegue y dashboard	Genera los archivos finales de predicciones (tiles parquet) que alimentan el dashboard Streamlit con el mapa de calor de disponibilidad.


â¸»

ğŸ’¡ Consejo: todos los notebooks registran sus resultados en carpetas versionadas (reports/, models/, outputs/), lo que permite reconstruir cualquier etapa del pipeline y comparar configuraciones sin reentrenar completamente el modelo.



âš™ï¸ Scripts principales â€” Carpeta src/

Los scripts dentro de src/ implementan las funciones principales del pipeline de entrenamiento, evaluaciÃ³n y despliegue.
Cada uno puede ejecutarse desde CLI o ser importado por los notebooks, garantizando modularidad y reproducibilidad.

Script	DescripciÃ³n
prepare_features.py	Genera el dataset model-ready: limpieza, cÃ¡lculo de lags, rolling windows y variables estacionales.
split_time.py	Realiza la divisiÃ³n temporal en conjuntos de entrenamiento, validaciÃ³n y test, respetando la secuencia cronolÃ³gica.
train.py	Entrena el modelo base o realiza pruebas de referencia previas al AutoML.
automl_pycaret.py	Implementa el flujo AutoML usando PyCaret, entrenando mÃºltiples modelos y registrando resultados en MLflow.
automl_flaml.py	Alternativa AutoML ligera basada en FLAML; busca hiperparÃ¡metros Ã³ptimos minimizando costo computacional.
backtest_mlflow.py	Ejecuta validaciones cruzadas temporales (rolling backtest) y almacena mÃ©tricas en MLflow.
compare_and_register.py	Compara los modelos generados por diferentes frameworks (PyCaret / FLAML) y registra el mejor.
register_best.py	Registra en MLflow y/o en disco local el modelo final aprobado para producciÃ³n.
predict_batch.py	Genera predicciones por lotes y exporta los resultados en outputs/predictions/*.parquet.
make_tiles.py	Convierte las predicciones en tiles espaciales listos para ser consumidos por el dashboard.


â¸»

ğŸ’¡ Nota: todos los scripts utilizan rutas relativas y configuraciÃ³n centralizada, por lo que se recomienda ejecutar los comandos desde la raÃ­z del proyecto o a travÃ©s del Makefile.



Excelente, te dejo el texto actualizado y adaptado a la versiÃ³n moderna del proyecto (post-reestructuraciÃ³n de notebooks y scripts), listo para pegar en tu ONBOARDING.md.
Mantiene tu estilo, emojis y formato limpio, pero con referencias actualizadas a src/ y a los nuevos nombres de notebooks.

â¸»

âš¡ï¸ 3.3. Flujo resumido

1ï¸âƒ£ Ingesta: data/raw â†’ data/curated
2ï¸âƒ£ Features: curated â†’ model_ready.parquet
3ï¸âƒ£ Entrenamiento: notebooks PASO_6* o scripts src/automl_pycaret.py / src/automl_flaml.py â†’ modelo final .pkl
4ï¸âƒ£ EvaluaciÃ³n: mÃ©tricas generadas en reports/
5ï¸âƒ£ PredicciÃ³n: src/predict_batch.py â†’ outputs/predictions/ y outputs/tiles/
6ï¸âƒ£ App: visualizaciÃ³n interactiva con Streamlit

â¸»

ğŸ§  4. Re-entrenar el modelo (Camino Dorado)

1ï¸âƒ£ Confirmar data
Archivo base:
data/curated/ecobici_model_ready.parquet
(Si no existe, ejecutar PASO_1 y PASO_2 o el script src/prepare_features.py.)

2ï¸âƒ£ Entrenar (AutoML)
Abrir el notebook PASO_6A_AutoML_con_PyCaret.ipynb o PASO_6B_AutoML_Flami.ipynb.
Al finalizar, el mejor modelo se guarda en:
models/best_model.pkl

3ï¸âƒ£ Generar predicciones batch

python src/predict_batch.py \
  --model "models/best_model.pkl" \
  --input "data/curated/ecobici_model_ready.parquet" \
  --stations "data/curated/station_information.parquet" \
  --horizons 1 3 6 12 \
  --asof "2025-10-25 10:00:00"

4ï¸âƒ£ Ejecutar la app

streamlit run app/main.py


â¸»

ğŸ§© 5. PersonalizaciÃ³n
	â€¢	Config: config/config.yaml
	â€¢	Rutas: datos, horizontes, estaciÃ³n por defecto
	â€¢	App: app/main.py
	â€¢	Colores: umbrales del semÃ¡foro y layout
	â€¢	Modelos: notebooks PASO_6* o scripts src/automl_*.py
	â€¢	MÃ©tricas: cambiar RMSE, MAE, RÂ² o semilla en YAML o Makefile

â¸»

ğŸ§¾ 6. MÃ©tricas y reportes generados

Archivo	DescripciÃ³n
reports/backtest_metrics_by_horizon.csv	Resultados por horizonte (1â€“3â€“6â€“12 h)
reports/error_by_hour_and_horizon.csv	AnÃ¡lisis horario del error
reports/holdout_month_metrics.csv	ValidaciÃ³n realista (Ãºltimo mes disponible)
reports/spatial_generalization.csv	(Opcional) EvaluaciÃ³n espacial de estaciones


â¸»

ğŸ¤ 7. ContribuciÃ³n (opcional)

1ï¸âƒ£ Crear rama nueva

git checkout -b feat/<descripcion>

2ï¸âƒ£ Agregar commits

git add .
git commit -m "feat: descripciÃ³n corta del cambio"

3ï¸âƒ£ Subir rama y abrir PR

git push origin feat/<descripcion>

4ï¸âƒ£ Checklist antes del merge
	â€¢	âœ… Entorno reproducible (make verify-env)
	â€¢	âœ… Reports actualizados
	â€¢	âœ… App funcionando con nuevo modelo

â¸»

ğŸ§­ 8. Estructura general del repositorio

â”œâ”€â”€ app/                     # Dashboard Streamlit
â”œâ”€â”€ config/                  # Archivos YAML de configuraciÃ³n
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Datos crudos (bronze)
â”‚   â”œâ”€â”€ curated/             # Datos curados (silver/gold)
â”‚   â””â”€â”€ predictions/         # Resultados de predicciones batch
â”œâ”€â”€ docs/                    # DocumentaciÃ³n del proyecto
â”œâ”€â”€ models/                  # Modelos entrenados
â”œâ”€â”€ notebooks/               # Jupyter Notebooks por etapa
â”œâ”€â”€ outputs/                 # Predicciones y tiles para el dashboard
â”œâ”€â”€ reports/                 # MÃ©tricas y evaluaciones
â”œâ”€â”€ src/                     # Scripts reproducibles (entrenamiento, batch, tiles)
â”œâ”€â”€ Makefile                 # Atajos de flujo (make verify-env, make app, etc.)
â”œâ”€â”€ environment.yml          # Dependencias Conda
â””â”€â”€ README.md


â¸»

ğŸ§© 9. Notas tÃ©cnicas y compatibilidad
	â€¢	Python: 3.10
	â€¢	Entorno: ecobici_automl
	â€¢	Frameworks: PyCaret, FLAML, H2O
	â€¢	Java: requerido JDK 11 para H2O (ver setup.sh)
	â€¢	Puertos: Streamlit â†’ 8501 Â· MLflow â†’ 5001
	â€¢	Sistema: probado en macOS y Linux

â¸»

ğŸ¯ 10. PrÃ³ximos pasos sugeridos
	â€¢	Revisar docs/FAA_avanzado.docx para entender el flujo avanzado
	â€¢	Probar la app localmente
	â€¢	(Opcional) Re-entrenar el modelo con otro horizonte
	â€¢	Crear tu primera Pull Request ğŸš€

â¸»

Autor: Roberto Inza
Repositorio acadÃ©mico: TP â€“ Fundamentos de Aprendizaje AutomÃ¡tico (Ecobici-AutoML)
Ãšltima actualizaciÃ³n: 26 Oct 2025

â¸»

ğŸ§° 11. Comandos rÃ¡pidos del Makefile

Comando	DescripciÃ³n
make verify-env	Verifica versiÃ³n de Python, librerÃ­as clave y config YAML
make repo-tree	Genera docs/dev/repo_tree.txt
make features	Ejecuta pipeline de features (etapa 02)
make train	Entrena modelo AutoML (PyCaret por defecto)
make predict	Genera predicciones batch y tiles (src/predict_batch.py)
make app	Inicia app Streamlit (app/main.py)
make mlflow-ui	Abre interfaz local de MLflow (localhost:5001)
make clean	Limpia outputs temporales y logs
make freeze	Exporta dependencias (requirements_freeze.txt)

ğŸ’¡ Tip:
PodÃ©s encadenar comandos:

make features && make train && make predict && make app


