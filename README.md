Â¡genial! acÃ¡ tenÃ©s un README.md listo para pegar en la raÃ­z del repo. EstÃ¡ pensado para que quien haga fork/clone pueda levantar todo desde cero y reproducir el pipeline end-to-end, con notas de AutoML, predicciÃ³n batch, tiles y (opcional) dashboard.

â¸»

Ecobici-AutoML

Pipeline reproducible para pronÃ³stico de disponibilidad de bicicletas por estaciÃ³n y mÃºltiples horizontes horarios. Incluye preparaciÃ³n de datos sin fuga, split temporal, baseline, AutoML (PyCaret/FLAML), backtesting con MLflow, predicciÃ³n batch multi-horizonte y generaciÃ³n de tiles para un heatmap.

ğŸ”§ Empezar desde cero (fork/clone)
	1.	Clonar el repo

git clone https://github.com/<tu_usuario>/ecobici_automl.git
cd ecobici_automl

	2.	Crear entorno (Conda recomendado)

conda env create -f environment.yml
conda activate ecobici_automl

	3.	Estructura mÃ­nima de carpetas

make setup

Esto crea data/{raw,interim,curated,...}, reports/, models/, predictions/, tiles/, etc.
	4.	Colocar datos de entrada

	â€¢	UbicÃ¡ tu parquet â€œcrudoâ€ en data/raw/status_clean.parquet.
	â€¢	(Opcional) data/curated/station_information.parquet con station_id, lat, lon, name (para tiles).

Si no tenÃ©s station_information.parquet, podÃ©s empezar sin tiles y agregarlo despuÃ©s.

	5.	Verificar entorno

make verify-env

	6.	Correr el pipeline base (Pasos 1â†’2â†’3)

make all

Esto:
	â€¢	Prepara features sin fuga â†’ data/curated/ecobici_model_ready.parquet
	â€¢	Crea splits temporales â†’ data/splits/{train,val,test}.parquet
	â€¢	Entrena baseline (RandomForest) â†’ modelo en models/03D y mÃ©tricas en reports/

	7.	Backtesting + MLflow (Paso 5)

make backtest
make mlflow-ui   # abre la UI en http://127.0.0.1:5001

	8.	AutoML (Paso 6)

	â€¢	PyCaret (script):

make automl-pycaret

Guarda modelo ganador en models/03A_pycaret/pycaret_best_model.pkl
MÃ©tricas acumuladas en reports/automl_metrics_by_split.csv
	â€¢	FLAML (opcional):
si activÃ¡s el target FLAML, generarÃ¡ models/06_flaml/flaml_automl.pkl y actualizarÃ¡ reports/automl_bench.csv.

	9.	PredicciÃ³n batch + tiles (Paso 8)

make predict
make tiles

	â€¢	make predict genera predictions/predictions_YYYY-MM-DD-HHh.parquet y un alias predictions/latest.parquet.
	â€¢	make tiles fusiona predicciones con coordenadas para heatmap â†’ tiles/tiles_YYYY-MM-DD-HHh.parquet con alias tiles/latest.parquet.

	10.	Dashboard (opcional)
Si aÃ±adÃ­s la app de Streamlit:

make app


â¸»

ğŸ—‚ï¸ Estructura (resumen)

ecobici_automl/
â”œâ”€â”€ app/                      # (opcional) dashboard Streamlit
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # status_clean.parquet (input crudo)
â”‚   â”œâ”€â”€ curated/              # ecobici_model_ready.parquet, station_information.parquet
â”‚   â””â”€â”€ splits/               # train/val/test.parquet
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ 03D/                  # baseline RF
â”‚   â””â”€â”€ 03A_pycaret/          # pycaret_best_model.pkl
â”œâ”€â”€ predictions/              # predicciones batch + latest.parquet
â”œâ”€â”€ tiles/                    # tiles para heatmap + latest.parquet
â”œâ”€â”€ notebooks/                # paso a paso reproducible
â”œâ”€â”€ reports/                  # mÃ©tricas, backtest, automl_bench, etc.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ prepare_features.py   # Paso 1
â”‚   â”œâ”€â”€ split_time.py         # Paso 2
â”‚   â”œâ”€â”€ train.py              # Paso 3 (baseline)
â”‚   â”œâ”€â”€ backtest_mlflow.py    # Paso 5
â”‚   â”œâ”€â”€ automl_pycaret.py     # Paso 6 (PyCaret)
â”‚   â”œâ”€â”€ automl_flaml.py       # Paso 6 (FLAML) [opcional]
â”‚   â”œâ”€â”€ model_select.py       # Paso 7 (registry/promociÃ³n) [opcional]
â”‚   â”œâ”€â”€ predict_batch.py      # Paso 8.1
â”‚   â””â”€â”€ make_tiles.py         # Paso 8.2
â”œâ”€â”€ environment.yml
â””â”€â”€ Makefile


â¸»

ğŸ§µ Flujo por pasos (resumen)
	1.	Paso 1 â€” Features: limpieza mÃ­nima + expansiÃ³n segura de columnas tipo JSON y one-hot de baja cardinalidad â†’ solo numÃ©ricas para modelos tradicionales.
	2.	Paso 2 â€” Split temporal: train/val/test respetando cronologÃ­a (sin fuga).
	3.	Paso 3 â€” Baseline: RandomForest + baseline lag1 comparativo.
	4.	Paso 4 â€” PredicciÃ³n recursiva (en notebooks): prueba multi-horizonte usando lags simulados.
	5.	Paso 5 â€” Backtesting + MLflow: expanding window y tracking de mÃ©tricas/artefactos.
	6.	Paso 6 â€” AutoML: PyCaret / FLAML con validaciÃ³n temporal y registro en reports/.
	7.	Paso 7 â€” SelecciÃ³n/Registry (opcional): elegir mejor por mÃ©trica y registrar en MLflow Model Registry.
	8.	Paso 8 â€” Serving batch + tiles: predict_batch.py â†’ make_tiles.py para dashboard.
	9.	Paso 9 â€” OrquestaciÃ³n/CI (opcional): GitHub Actions/Jenkins + checks de drift/calidad.
	10.	Paso 10 â€” DataOps/DVC (opcional): versionado de datasets/artefactos y remotes (S3/DagsHub).

â¸»

ğŸ§ª Comandos Ãºtiles (Makefile)

make help          # ver targets disponibles
make setup         # crear estructura mÃ­nima
make all           # Paso 1â†’2â†’3
make backtest      # Paso 5
make mlflow-ui     # abrir UI
make automl-pycaret# Paso 6 (PyCaret)
make predict       # Paso 8.1 â€” batch multi-horizonte
make tiles         # Paso 8.2 â€” tiles heatmap
make clean         # limpiar caches livianos


â¸»

ğŸ” Detalles clave

ASOF

Timestamp de referencia (p.ej. â€œ2025-10-25 13:00:00â€) desde el cual se generan predicciones hacia adelante. predict_batch.py armoniza timezone con tus datos para evitar errores tz-aware vs tz-naive.

Tiles

Archivo parquet con filas a nivel (station_id, timestamp_pred, h) y columnas lat, lon, yhat, etc. Se usa directo para mapas/heatmaps.

â¸»

ğŸ§¯ Troubleshooting comÃºn
	â€¢	tz-naive vs tz-aware en comparaciones
Asegurate de no mezclar timestamps con y sin zona horaria. El pipeline ya localiza ASOF segÃºn el tz de tus datos.
	â€¢	Feature names must match al predecir
Ocurre si el modelo fue entrenado con un set de features distinto.
SoluciÃ³n aplicada: predict_batch.py reindexa las features runtime al esquema exacto del train split (columnas y orden), rellena faltantes con 0 y descarta extras.
	â€¢	latest.parquet no encontrado al hacer tiles
UsÃ¡ make predict antes de make tiles. El Makefile crea/actualiza el alias predictions/latest.parquet.

â¸»

ğŸ—„ï¸ Git, datos y privacidad

Por defecto el .gitignore excluye:
	â€¢	*.parquet, *.pkl, mlruns/, predictions/, tiles/, data/raw/, data/interim/.
	â€¢	SubÃ­ a Git cÃ³digo y configs, no datos sensibles.
Si usÃ¡s DVC (opcional), podÃ©s versionar metadata de datasets y empujar a S3/DagsHub.

â¸»

ğŸ“Š MLflow

Todos los entrenamientos y backtests registran parÃ¡metros, mÃ©tricas y artefactos.
AbrÃ­ la UI con:

make mlflow-ui
# http://127.0.0.1:5001


â¸»

ğŸ§  AutoML
	â€¢	PyCaret: validaciÃ³n temporal (fold_strategy="timeseries") y sÃ³lo features numÃ©ricas para evitar problemas con tipos complejos.
	â€¢	FLAML: alternativa liviana con time budget configurable y logging a archivo.

PodÃ©s comparar ambos (y baseline) leyendo reports/automl_bench.csv / reports/automl_metrics_by_split.csv.

â¸»

ğŸ—ºï¸ Dashboard (opcional)

Con tiles/latest.parquet y predictions/latest.parquet podÃ©s construir:
	â€¢	Heatmap por estaciÃ³n, selector de horizonte (1,3,6,12h), tooltips con yhat.
	â€¢	Panel lateral con top estaciones por demanda/escasez.

â¸»

ğŸ“œ Licencia

ElegÃ­ y aÃ±adÃ­ una licencia en el repo (MIT/Apache-2.0, etc.) segÃºn corresponda.

â¸»

Â¿QuerÃ©s que te lo deje tambiÃ©n como archivo listo para commit con un mensaje sugerido?