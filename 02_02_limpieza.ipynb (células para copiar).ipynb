{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989357c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Configuración y utilidades\n",
    "# Celda 1 — Config y helpers\n",
    "from pathlib import Path\n",
    "import shutil, datetime, os, json\n",
    "\n",
    "# --- Config principal ---\n",
    "REPO = Path.cwd()  # Ejecutar desde la raíz del repo\n",
    "DRY_RUN = True     # Primero: simular. Luego ponelo en False para ejecutar.\n",
    "STAMP = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "ARCH = REPO / \"archive\" / f\"ARCH_{STAMP}\"\n",
    "\n",
    "# Carpetas “doradas”\n",
    "GOLD_DIRS = {\n",
    "    \"data\": [\"raw\", \"interim\", \"curated\", \"external\"],\n",
    "    \"outputs\": [\"models\", \"predictions\", \"tiles\", \"visuals\", \"metrics\"],\n",
    "    \"reports\": [\"experiments\", \"logs\", \"monitoring\"],\n",
    "}\n",
    "\n",
    "# Objetos a limpiar/mover (enfoque simplificación radical)\n",
    "NOTEBOOKS_MIRROR_DIRS = [\"data\",\"models\",\"monitoring\",\"notebooks\",\"predictions\",\"reports\",\"tiles\",\"visuals\"]\n",
    "H2O_PATTERNS = [\"GBM_grid_\", \"StackedEnsemble_\", \"h2o-genmodel.jar\"]\n",
    "MODEL_FOLDERS_TO_MOVE_OUT = [(\"models/outputs\", \"outputs/models\")]\n",
    "ROOT_MONITORING = (\"monitoring\", \"reports/monitoring\")\n",
    "DATA_LEGACY = [(\"data/processed\", \"data/interim\"), (\"data/training\", \"data/curated\")]\n",
    "\n",
    "# Archivos pesados/artefactos que suelen sobrar (se archivan)\n",
    "LARGE_EXTS = [\".zip\", \".jar\", \".pkl\"]  # en models/\n",
    "CATBOOST_ARTIFACTS_DIRS = [\"notebooks/catboost_info\"]\n",
    "CATBOOST_ARTIFACTS_GLOBS = [\"notebooks/catboost_*\"]\n",
    "\n",
    "# --- utilidades ---\n",
    "actions = []\n",
    "\n",
    "def ensure_dirs():\n",
    "    for base, subs in GOLD_DIRS.items():\n",
    "        for s in subs:\n",
    "            (REPO / base / s).mkdir(parents=True, exist_ok=True)\n",
    "    (ARCH / \"models_misc\").mkdir(parents=True, exist_ok=True)\n",
    "    (ARCH / \"notebooks_artifacts\" / \"catboost\").mkdir(parents=True, exist_ok=True)\n",
    "    (ARCH / \"outputs_old\").mkdir(parents=True, exist_ok=True)\n",
    "    (ARCH / \"root_misc\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def move_path(src: Path, dst: Path):\n",
    "    \"\"\"Mueve src→dst de forma segura (crea padres). Registra acción.\"\"\"\n",
    "    if not src.exists():\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    actions.append({\"op\":\"move\",\"from\":str(src.relative_to(REPO)),\"to\":str(dst.relative_to(REPO))})\n",
    "    if not DRY_RUN:\n",
    "        shutil.move(str(src), str(dst))\n",
    "\n",
    "def rsync_dir(src: Path, dst: Path, delete_src=True):\n",
    "    if not src.exists():\n",
    "        return\n",
    "    dst.mkdir(parents=True, exist_ok=True)\n",
    "    # mover todo el contenido\n",
    "    for p in src.glob(\"**/*\"):\n",
    "        # respeta estructura relativa\n",
    "        if p.is_file():\n",
    "            rel = p.relative_to(src)\n",
    "            target = dst / rel\n",
    "            target.parent.mkdir(parents=True, exist_ok=True)\n",
    "            actions.append({\"op\":\"copy\",\"from\":str(p.relative_to(REPO)),\"to\":str(target.relative_to(REPO))})\n",
    "            if not DRY_RUN:\n",
    "                shutil.copy2(p, target)\n",
    "    if delete_src:\n",
    "        actions.append({\"op\":\"rmdir\",\"path\":str(src.relative_to(REPO))})\n",
    "        if not DRY_RUN:\n",
    "            shutil.rmtree(src, ignore_errors=True)\n",
    "\n",
    "def add_gitignore_lines(lines):\n",
    "    gi = REPO / \".gitignore\"\n",
    "    existing = set()\n",
    "    if gi.exists():\n",
    "        existing = set(l.strip() for l in gi.read_text().splitlines() if l.strip())\n",
    "    new_lines = []\n",
    "    for ln in lines:\n",
    "        if ln not in existing:\n",
    "            new_lines.append(ln)\n",
    "    if new_lines:\n",
    "        actions.append({\"op\":\"append_gitignore\",\"lines\":new_lines})\n",
    "        if not DRY_RUN:\n",
    "            with gi.open(\"a\") as f:\n",
    "                for ln in new_lines:\n",
    "                    f.write(ln+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a7a623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acciones planificadas (simulación): 20\n",
      "{'op': 'rmdir', 'path': 'notebooks/data'}\n",
      "{'op': 'rmdir', 'path': 'notebooks/reports'}\n",
      "{'op': 'move', 'from': 'notebooks/catboost_1760613551.673151', 'to': 'archive/ARCH_20251024/notebooks_artifacts/catboost/catboost_1760613551.673151'}\n",
      "{'op': 'move', 'from': 'notebooks/catboost_1760613430.927209', 'to': 'archive/ARCH_20251024/notebooks_artifacts/catboost/catboost_1760613430.927209'}\n",
      "{'op': 'move', 'from': 'notebooks/catboost_1760613579.323601', 'to': 'archive/ARCH_20251024/notebooks_artifacts/catboost/catboost_1760613579.323601'}\n",
      "{'op': 'move', 'from': 'notebooks/catboost_1760613461.38568', 'to': 'archive/ARCH_20251024/notebooks_artifacts/catboost/catboost_1760613461.38568'}\n",
      "{'op': 'move', 'from': 'notebooks/catboost_1760613474.00322', 'to': 'archive/ARCH_20251024/notebooks_artifacts/catboost/catboost_1760613474.00322'}\n",
      "{'op': 'move', 'from': 'notebooks/catboost_1760613587.256147', 'to': 'archive/ARCH_20251024/notebooks_artifacts/catboost/catboost_1760613587.256147'}\n",
      "{'op': 'move', 'from': 'notebooks/catboost_1760613550.046567', 'to': 'archive/ARCH_20251024/notebooks_artifacts/catboost/catboost_1760613550.046567'}\n",
      "{'op': 'move', 'from': 'models/StackedEnsemble_AllModels_2_AutoML_2_20251015_231613.zip', 'to': 'archive/ARCH_20251024/models_misc/StackedEnsemble_AllModels_2_AutoML_2_20251015_231613.zip'}\n",
      "{'op': 'move', 'from': 'models/flaml_best_estimator_full_20251016_085213.pkl', 'to': 'archive/ARCH_20251024/models_misc/flaml_best_estimator_full_20251016_085213.pkl'}\n",
      "{'op': 'move', 'from': 'models/final_model_pycaret_pipeline.pkl', 'to': 'archive/ARCH_20251024/models_misc/final_model_pycaret_pipeline.pkl'}\n",
      "{'op': 'move', 'from': 'models/best_model_ecobici_log.pkl', 'to': 'archive/ARCH_20251024/models_misc/best_model_ecobici_log.pkl'}\n",
      "{'op': 'move', 'from': 'models/flaml_best_estimator_20251016_082101.pkl', 'to': 'archive/ARCH_20251024/models_misc/flaml_best_estimator_20251016_082101.pkl'}\n",
      "{'op': 'move', 'from': 'models/GBM_grid_1_AutoML_1_20251015_224927_model_1.zip', 'to': 'archive/ARCH_20251024/models_misc/GBM_grid_1_AutoML_1_20251015_224927_model_1.zip'}\n",
      "{'op': 'move', 'from': 'models/h2o-genmodel.jar', 'to': 'archive/ARCH_20251024/models_misc/h2o-genmodel.jar'}\n",
      "{'op': 'move', 'from': 'models/flaml_automl_20251016_082101.pkl', 'to': 'archive/ARCH_20251024/models_misc/flaml_automl_20251016_082101.pkl'}\n",
      "{'op': 'move', 'from': 'models/final_model_pycaret.pkl', 'to': 'archive/ARCH_20251024/models_misc/final_model_pycaret.pkl'}\n",
      "{'op': 'move', 'from': 'models/GBM_grid_1_AutoML_1_20251015_220355_model_14.zip', 'to': 'archive/ARCH_20251024/models_misc/GBM_grid_1_AutoML_1_20251015_220355_model_14.zip'}\n",
      "{'op': 'move', 'from': 'models/flaml_automl_full_20251016_085213.pkl', 'to': 'archive/ARCH_20251024/models_misc/flaml_automl_full_20251016_085213.pkl'}\n"
     ]
    }
   ],
   "source": [
    "#2) Plan de limpieza (definición de operaciones)\n",
    "# Celda 2 — Definir el plan (no ejecuta nada todavía)\n",
    "\n",
    "ensure_dirs()\n",
    "\n",
    "# 1) Normalizar data legacy → estándar\n",
    "for src_str, dst_str in DATA_LEGACY:\n",
    "    src, dst = REPO/src_str, REPO/dst_str\n",
    "    if src.exists():\n",
    "        move_path(src, dst)\n",
    "\n",
    "# 2) models/outputs → outputs/models\n",
    "for src_str, dst_str in MODEL_FOLDERS_TO_MOVE_OUT:\n",
    "    src, dst = REPO/src_str, REPO/dst_str\n",
    "    if src.exists():\n",
    "        # mover contenido y borrar fuente\n",
    "        rsync_dir(src, dst, delete_src=True)\n",
    "\n",
    "# 3) monitoring (raíz) → reports/monitoring\n",
    "src, dst = REPO/ROOT_MONITORING[0], REPO/ROOT_MONITORING[1]\n",
    "if Path(src).exists():\n",
    "    rsync_dir(Path(src), REPO/dst, delete_src=True)\n",
    "\n",
    "# 4) notebooks/* espejos → mover a oficiales y borrar duplicados\n",
    "for d in NOTEBOOKS_MIRROR_DIRS:\n",
    "    src_dir = REPO/\"notebooks\"/d\n",
    "    if src_dir.exists():\n",
    "        target = None\n",
    "        if d in [\"predictions\",\"tiles\",\"visuals\"]:\n",
    "            target = REPO/\"outputs\"/d\n",
    "        elif d in [\"reports\"]:\n",
    "            target = REPO/\"reports\"\n",
    "        elif d in [\"models\"]:\n",
    "            target = REPO/\"models\"\n",
    "        elif d in [\"monitoring\"]:\n",
    "            target = REPO/\"reports\"/\"monitoring\"\n",
    "        elif d in [\"data\"]:\n",
    "            target = REPO/\"data\"\n",
    "        elif d in [\"notebooks\"]:\n",
    "            # bucle notebooks/notebooks → borrar\n",
    "            actions.append({\"op\":\"rmdir\",\"path\":str(src_dir.relative_to(REPO))})\n",
    "            if not DRY_RUN:\n",
    "                shutil.rmtree(src_dir, ignore_errors=True)\n",
    "            continue\n",
    "        if target:\n",
    "            rsync_dir(src_dir, target, delete_src=True)\n",
    "\n",
    "# 5) Artefactos CatBoost → archive\n",
    "for d in CATBOOST_ARTIFACTS_DIRS:\n",
    "    p = REPO/d\n",
    "    if p.exists():\n",
    "        move_path(p, ARCH/\"notebooks_artifacts\"/\"catboost\"/p.name)\n",
    "\n",
    "for pattern in CATBOOST_ARTIFACTS_GLOBS:\n",
    "    for p in REPO.glob(pattern):\n",
    "        move_path(p, ARCH/\"notebooks_artifacts\"/\"catboost\"/p.name)\n",
    "\n",
    "# 6) H2O/FLAML/PyCaret artefactos grandes en models/ → archive\n",
    "models_dir = REPO/\"models\"\n",
    "if models_dir.exists():\n",
    "    for p in models_dir.iterdir():\n",
    "        if p.is_file() and p.suffix.lower() in LARGE_EXTS:\n",
    "            move_path(p, ARCH/\"models_misc\"/p.name)\n",
    "        if p.is_dir():\n",
    "            # mover directorios H2O típicos (GBM_grid_*, StackedEnsemble_*)\n",
    "            if any(p.name.startswith(pref) for pref in H2O_PATTERNS if pref.endswith(\"_\") or True):\n",
    "                if p.name.startswith(\"GBM_grid_\") or p.name.startswith(\"StackedEnsemble_\"):\n",
    "                    move_path(p, ARCH/\"models_misc\"/p.name)\n",
    "\n",
    "# 7) Ignorar adecuadamente\n",
    "add_gitignore_lines([\n",
    "    \".DS_Store\",\n",
    "    \".ipynb_checkpoints/\",\n",
    "    \"data/\",\n",
    "    \"outputs/\",\n",
    "    \"mlruns/\",\n",
    "    \"archive/\",\n",
    "    \"*.log\"\n",
    "])\n",
    "\n",
    "# 8) Guardar un “informe” previo (acciones planificadas)\n",
    "REPORT = REPO/\"docs\"/\"dev\"/f\"PLAN_02_2_{STAMP}.json\"\n",
    "if not DRY_RUN:\n",
    "    REPORT.write_text(json.dumps(actions, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    # En DRY_RUN, igualmente lo mostramos en pantalla\n",
    "    print(f\"Acciones planificadas (simulación): {len(actions)}\")\n",
    "    for a in actions[:30]:\n",
    "        print(a)\n",
    "    if len(actions) > 30:\n",
    "        print(f\"... (+{len(actions)-30} más)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050b6559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Limpieza aplicada. Acciones: 20\n",
      "→ Informe: /Users/ri1965/Desktop/ecobici-automl/docs/dev/APLICACION_02_2_20251024.json\n"
     ]
    }
   ],
   "source": [
    "# 3) Ejecutar de verdad (cambiar DRY_RUN = False y correr)\n",
    "# Celda 3 — Ejecutar\n",
    "DRY_RUN = False\n",
    "\n",
    "# Re-ejecutar el mismo plan (para que aplique las acciones)\n",
    "# Nota: repetimos las definiciones mínimas necesarias\n",
    "actions_exec = []\n",
    "\n",
    "def run_move_path(src: Path, dst: Path):\n",
    "    if not src.exists(): \n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    actions_exec.append({\"op\":\"move\",\"from\":str(src.relative_to(REPO)),\"to\":str(dst.relative_to(REPO))})\n",
    "    shutil.move(str(src), str(dst))\n",
    "\n",
    "def run_rsync_dir(src: Path, dst: Path, delete_src=True):\n",
    "    if not src.exists():\n",
    "        return\n",
    "    dst.mkdir(parents=True, exist_ok=True)\n",
    "    for p in src.glob(\"**/*\"):\n",
    "        if p.is_file():\n",
    "            rel = p.relative_to(src)\n",
    "            target = dst / rel\n",
    "            target.parent.mkdir(parents=True, exist_ok=True)\n",
    "            actions_exec.append({\"op\":\"copy\",\"from\":str(p.relative_to(REPO)),\"to\":str(target.relative_to(REPO))})\n",
    "            shutil.copy2(p, target)\n",
    "    if delete_src:\n",
    "        actions_exec.append({\"op\":\"rmdir\",\"path\":str(src.relative_to(REPO))})\n",
    "        shutil.rmtree(src, ignore_errors=True)\n",
    "\n",
    "# 1) data legacy\n",
    "for src_str, dst_str in DATA_LEGACY:\n",
    "    src, dst = REPO/src_str, REPO/dst_str\n",
    "    if src.exists():\n",
    "        run_move_path(src, dst)\n",
    "\n",
    "# 2) models/outputs → outputs/models\n",
    "for src_str, dst_str in MODEL_FOLDERS_TO_MOVE_OUT:\n",
    "    src, dst = REPO/src_str, REPO/dst_str\n",
    "    if src.exists():\n",
    "        run_rsync_dir(src, dst, delete_src=True)\n",
    "\n",
    "# 3) monitoring raíz → reports/monitoring\n",
    "src, dst = REPO/ROOT_MONITORING[0], REPO/ROOT_MONITORING[1]\n",
    "if Path(src).exists():\n",
    "    run_rsync_dir(Path(src), REPO/dst, delete_src=True)\n",
    "\n",
    "# 4) notebooks espejos\n",
    "for d in NOTEBOOKS_MIRROR_DIRS:\n",
    "    src_dir = REPO/\"notebooks\"/d\n",
    "    if src_dir.exists():\n",
    "        target = None\n",
    "        if d in [\"predictions\",\"tiles\",\"visuals\"]:\n",
    "            target = REPO/\"outputs\"/d\n",
    "        elif d in [\"reports\"]:\n",
    "            target = REPO/\"reports\"\n",
    "        elif d in [\"models\"]:\n",
    "            target = REPO/\"models\"\n",
    "        elif d in [\"monitoring\"]:\n",
    "            target = REPO/\"reports\"/\"monitoring\"\n",
    "        elif d in [\"data\"]:\n",
    "            target = REPO/\"data\"\n",
    "        elif d in [\"notebooks\"]:\n",
    "            actions_exec.append({\"op\":\"rmdir\",\"path\":str(src_dir.relative_to(REPO))})\n",
    "            shutil.rmtree(src_dir, ignore_errors=True)\n",
    "            continue\n",
    "        if target:\n",
    "            run_rsync_dir(src_dir, target, delete_src=True)\n",
    "\n",
    "# 5) CatBoost → archive\n",
    "for d in CATBOOST_ARTIFACTS_DIRS:\n",
    "    p = REPO/d\n",
    "    if p.exists():\n",
    "        run_move_path(p, ARCH/\"notebooks_artifacts\"/\"catboost\"/p.name)\n",
    "\n",
    "for pattern in CATBOOST_ARTIFACTS_GLOBS:\n",
    "    for p in REPO.glob(pattern):\n",
    "        run_move_path(p, ARCH/\"notebooks_artifacts\"/\"catboost\"/p.name)\n",
    "\n",
    "# 6) models: artefactos grandes → archive\n",
    "models_dir = REPO/\"models\"\n",
    "if models_dir.exists():\n",
    "    for p in models_dir.iterdir():\n",
    "        if p.is_file() and p.suffix.lower() in LARGE_EXTS:\n",
    "            run_move_path(p, ARCH/\"models_misc\"/p.name)\n",
    "        if p.is_dir():\n",
    "            if p.name.startswith(\"GBM_grid_\") or p.name.startswith(\"StackedEnsemble_\"):\n",
    "                run_move_path(p, ARCH/\"models_misc\"/p.name)\n",
    "\n",
    "# 7) .gitignore — apéndice\n",
    "gi_lines = [\n",
    "    \".DS_Store\",\n",
    "    \".ipynb_checkpoints/\",\n",
    "    \"data/\",\n",
    "    \"outputs/\",\n",
    "    \"mlruns/\",\n",
    "    \"archive/\",\n",
    "    \"*.log\"\n",
    "]\n",
    "gi = REPO / \".gitignore\"\n",
    "existing = set()\n",
    "if gi.exists():\n",
    "    existing = set(l.strip() for l in gi.read_text().splitlines() if l.strip())\n",
    "with gi.open(\"a\") as f:\n",
    "    for ln in gi_lines:\n",
    "        if ln not in existing:\n",
    "            f.write(ln+\"\\n\")\n",
    "\n",
    "# 8) Guardar informe de ejecución\n",
    "REPORT = REPO/\"docs\"/\"dev\"/f\"APLICACION_02_2_{STAMP}.json\"\n",
    "with REPORT.open(\"w\") as f:\n",
    "    json.dump(actions_exec, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Limpieza aplicada. Acciones: {len(actions_exec)}\\n→ Informe: {REPORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1f864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol (nivel 2):\n",
      "├── .git\n",
      "├── .ipynb_checkpoints\n",
      "├── app\n",
      "├── archive\n",
      "├── config\n",
      "├── data\n",
      "├── docs\n",
      "├── envs\n",
      "├── models\n",
      "├── notebooks\n",
      "├── outputs\n",
      "├── reports\n",
      "├── scripts\n",
      "├── src\n",
      "├── tools\n",
      "\n",
      "Git status:\n",
      "En la rama master\n",
      "Cambios no rastreados para el commit:\n",
      "  (usa \"git add/rm <archivo>...\" para actualizar a lo que se le va a hacer commit)\n",
      "  (usa \"git restore <archivo>...\" para descartar los cambios en el directorio de trabajo)\n",
      "\tmodificados:     Makefile\n",
      "\tmodificados:     docs/dev/ESTRUCTURA_ACTUAL.txt\n",
      "\tmodificados:     docs/dev/repo_tree.txt\n",
      "\tborrados:        models/GBM_grid_1_AutoML_1_20251015_220355_model_14.zip\n",
      "\tborrados:        models/GBM_grid_1_AutoML_1_20251015_224927_model_1.zip\n",
      "\tborrados:        models/StackedEnsemble_AllModels_2_AutoML_2_20251015_231613.zip\n",
      "\tborrados:        models/best_model_ecobici_log.pkl\n",
      "\tborrados:        models/final_model_pycaret.pkl\n",
      "\tborrados:        models/final_model_pycaret_pipeline.pkl\n",
      "\tborrados:        models/flaml_automl_20251016_082101.pkl\n",
      "\tborrados:        models/flaml_automl_full_20251016_085213.pkl\n",
      "\tborrados:        models/flaml_best_estimator_20251016_082101.pkl\n",
      "\tborrados:        models/flaml_best_estimator_full_20251016_085213.pkl\n",
      "\tborrados:        models/h2o-genmodel.jar\n",
      "\tmodificados:     readme_nuevo.md\n",
      "\n",
      "Archivos sin seguimiento:\n",
      "  (usa \"git add <archivo>...\" para incluirlo a lo que será confirmado)\n",
      "\t\"02_02_limpieza.ipynb (c\\303\\251lulas para copiar).ipynb\"\n",
      "\tdocs/dev/APLICACION_02_2_20251024.json\n",
      "\tdocs/dev/ARCHIVOS_PESADOS.txt\n",
      "\tdocs/dev/DUPLICADOS_NOTEBOOKS.txt\n",
      "\tdocs/dev/GIT_STATUS_02_1.txt\n",
      "\tnotebooks/.gitignore\n",
      "\n",
      "sin cambios agregados al commit (usa \"git add\" y/o \"git commit -a\")\n",
      "\n",
      "Ignorados (resumen):\n",
      "M Makefile\n",
      " M docs/dev/ESTRUCTURA_ACTUAL.txt\n",
      " M docs/dev/repo_tree.txt\n",
      " D models/GBM_grid_1_AutoML_1_20251015_220355_model_14.zip\n",
      " D models/GBM_grid_1_AutoML_1_20251015_224927_model_1.zip\n",
      " D models/StackedEnsemble_AllModels_2_AutoML_2_20251015_231613.zip\n",
      " D models/best_model_ecobici_log.pkl\n",
      " D models/final_model_pycaret.pkl\n",
      " D models/final_model_pycaret_pipeline.pkl\n",
      " D models/flaml_automl_20251016_082101.pkl\n",
      " D models/flaml_automl_full_20251016_085213.pkl\n",
      " D models/flaml_best_estimator_20251016_082101.pkl\n",
      " D models/flaml_best_estimator_full_20251016_085213.pkl\n",
      " D models/h2o-genmodel.jar\n",
      " M readme_nuevo.md\n",
      "?? \"02_02_limpieza.ipynb (c\\303\\251lulas para copiar).ipynb\"\n",
      "?? docs/dev/APLICACION_02_2_20251024.json\n",
      "?? docs/dev/ARCHIVOS_PESADOS.txt\n",
      "?? docs/dev/DUPLICADOS_NOTEBOOKS.txt\n",
      "?? docs/dev/GIT_STATUS_02_1.txt\n",
      "?? notebooks/.gitignore\n",
      "!! .DS_Store\n",
      "!! archive/ARCH_20251024/mlruns/\n",
      "!! archive/ARCH_20251024/models_misc/\n",
      "!! data/\n",
      "!! docs/.DS_Store\n",
      "!! logs.log\n",
      "!! notebooks/.DS_Store\n",
      "!! notebooks/.ipynb_checkpoints/\n",
      "!! notebooks/logs.log\n",
      "!! outputs/\n"
     ]
    }
   ],
   "source": [
    "# 4) Post-chequeo (estructura y estado)\n",
    "# Celda 4 — Verificación rápida\n",
    "from subprocess import run, PIPE\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    out = run(cmd, shell=True, stdout=PIPE, stderr=PIPE, text=True)\n",
    "    return out.stdout.strip()\n",
    "\n",
    "print(\"Árbol (nivel 2):\")\n",
    "print(run_cmd(\"python - << 'PY'\\nfrom pathlib import Path\\nimport os\\nroot='.'\\nfor p in sorted([d for d in Path(root).iterdir() if d.is_dir()]):\\n    print('├──', p.name)\\nPY\"))\n",
    "\n",
    "print(\"\\nGit status:\")\n",
    "print(run_cmd(\"git status\"))\n",
    "\n",
    "print(\"\\nIgnorados (resumen):\")\n",
    "print(run_cmd(\"git status --ignored -s | sed -n '1,120p'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5c59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EcoBici (Py3.10)",
   "language": "python",
   "name": "ecobici_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
